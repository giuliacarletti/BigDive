{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce  \n",
    "\n",
    "**Map Reduce** è un framework inventato e brevettato da Google per supportare la computazione distribuita su una grande mole di dati, nasce dall'ispirazione delle funzioni **map** e **reduce** del functional programming.\n",
    "\n",
    "Il processo si divide in due steps:\n",
    "- MAPPING: L'input viene diviso in sotto parti finchè non raggiunge la dimensione minima processuale, restituisce un risultato\n",
    "\n",
    "- REDUCE: Ogni valore derivato dal processo di mapping viene processato effettuando una **join** di tutti i valori in un singolo risultato aggregato.\n",
    "\n",
    "\n",
    "<img src=\"files/MapReduce.jpeg\" width=\"640\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Why Map Reduce\n",
    "\n",
    "Map Reduce in 140 Caratteri (From Twitter):\n",
    "\n",
    "* Some computing tasks can be split up into small chunks, processed simultaneously, and then reassembled at the end\n",
    "\n",
    "* MapReduce is the algorithm google uses to allow many machines to break a problem into smaller chunks and process data.\n",
    "\n",
    "* Allows you to quickly process very large amounts of data very quickly using distributed computing, often using cheap hardware\n",
    " \n",
    "* Map reduce is important because it allows for problems to be distributed rather easily.\n",
    " \n",
    "* Parallelism and multi-core\n",
    " \n",
    "* Problem hard. Many computers work on problem. Chop problem up (map). Merge results (reduce). Works for cloud or massive multi-core.\n",
    " \n",
    " \n",
    "## Concetti Chiave\n",
    "\n",
    "1) **Parallelismo & multicore**: MapReduce è ottimo per lavorare con grandi dataset su un cluster distribuito grazie alle potenzialità del framework, in grado di spezzare un grande problema in tanti piccoli sotto-problemi, effettuando un **merge** di tutti i risultati come step finale.\n",
    " \n",
    "2) **Commodity-hardware**: MapReduce può funzionare con diversi linguaggi di programmazione senza nessun requisito hardware particolare. Per questa ragione MapReduce è considerata una soluzione a basso costo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce Examples\n",
    "\n",
    "MapReduce diventa realmente rilavante nel momento in cui un singolo computer non è più sufficiente per garantire l'eleborazione del dataset a causa dell'elevato volume o complessità. Questo è il motivo per cui molti vendor di soluzione Cloud hanno integrato soluzione MapReduce nel loro catalogo di servizi.\n",
    "\n",
    "Vedremo successivamente come utilizzare sistemi in Cloud per l'elaborazione di dati distribuita su molteplici macchine (nel caso pratico utilizzeremo AWS - Amazon Web Services). Il fatto di essere *cloud-ready* è un fattore molto importante nel momento in cui si comincerà a lavorare sui dati, motivo per cui il paradigma MapReduce è diventato cosi diffuso.\n",
    "\n",
    "Siccome MapReduce permette di utilizzare diversi linguaggi / framework, andremo a utilizzare librerie Python e MongoDB (il quale implementa nativamente logiche di MapReduce) e vedremo un introduzione a Hadoop e una demo di Spark.\n",
    "\n",
    "Esempi di utilizzo:\n",
    "\n",
    "- WordCount\n",
    "- Rimozione di duplicati all'interno del dataset (data-cleaning)\n",
    "- trasposizione di matrici\n",
    "- Followers dei followers\n",
    "- Calcolo di statistiche\n",
    "- Recommendation systems\n",
    "- ...\n",
    "\n",
    "## Conclusione\n",
    "\n",
    "MapReduce è quindi un tool che potremmo usare durante la presentazione o l'esplorazione del dataset. A noi, come tanti data scientist, piace perchè:\n",
    "\n",
    "- Ottimo strumento per lavorare sui dati in rapidamente\n",
    "- Ci permette di scalare facilmente orizzontalmente\n",
    "- Non ci serve sapere tutti i segreti che sono dietro a MapReduce, lo usiamo, funziona, è ben documentato ed è quindi, per noi, più che sufficiente :)\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "Qui --> [LINK](http://had00b.blogspot.co.uk/2013/08/mapreduce-gentle-introduction.html) potete trovare un introduzione più strutturata a MapReduce!\n",
    "\n",
    "Qui --> [LINK](https://gigaom.com/2013/03/04/the-history-of-hadoop-from-4-nodes-to-the-future-of-data/) potete trovare una introduzione su Hadoop (vedi dopo per maggiori informazioni)\n",
    "\n",
    "Per maggiori esempi o informazioni, trovate esempi, documentazione e tutorial [QUI](https://github.com/alexcomu/hadoop-mapreduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Practice Example - Word Count\n",
    "\n",
    "<img src=\"files/MapReduce_example.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Esempio senza l'utilizzo di MapReduce\n",
    "\n",
    "L'obiettivo del problema è di calcolare la somma del doppio di una serie di numeri.\n",
    "\n",
    "Quindi, se abbiamo come input **[1, 2, 3]** il risultato sarà: **2+4+6 -> 12**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999000\n"
     ]
    }
   ],
   "source": [
    "# Genero una lista lunga 1000\n",
    "numbers = range(1000)\n",
    "\n",
    "def doubled_sum(values):\n",
    "    total = 0 # inizializzo una variabile per la somma\n",
    "    for n in values:\n",
    "        # per ogni numero calcolo il doppio e effettuo la somma\n",
    "        # calcola il doppio di ogni numero e lo somma al totale\n",
    "        total += n*2\n",
    "    # Una volta terminato il ciclo, restituisco il valore\n",
    "    return total\n",
    "\n",
    "print doubled_sum(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esempio utilizzando MapReduce\n",
    "\n",
    "Siccome Python supporta il paradigma del **functional programmin**, si ha a disposizione tutto il necessario per implementare il paradigma **map-reduce** direttamente in linguaggio python nativo.\n",
    "\n",
    "Entrambi gli step possono essere eseguiti più volte (L'output del reducer può diventare l'input di un ulteriore mapper e cosi via).\n",
    "\n",
    "Ecco gli step da seguire per risolvere il problema:\n",
    "\n",
    "### Mapper\n",
    "\n",
    "Ha il compito di effettuare il mapping di ogni singolo input, restituendo come output il suo valore moltiplicato per 2\n",
    "\n",
    "### Reducer\n",
    "\n",
    "Ha il compito di effettuare la somma degli output multipli del mapper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222, 224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250, 252, 254, 256, 258, 260, 262, 264, 266, 268, 270, 272, 274, 276, 278, 280, 282, 284, 286, 288, 290, 292, 294, 296, 298, 300, 302, 304, 306, 308, 310, 312, 314, 316, 318, 320, 322, 324, 326, 328, 330, 332, 334, 336, 338, 340, 342, 344, 346, 348, 350, 352, 354, 356, 358, 360, 362, 364, 366, 368, 370, 372, 374, 376, 378, 380, 382, 384, 386, 388, 390, 392, 394, 396, 398, 400, 402, 404, 406, 408, 410, 412, 414, 416, 418, 420, 422, 424, 426, 428, 430, 432, 434, 436, 438, 440, 442, 444, 446, 448, 450, 452, 454, 456, 458, 460, 462, 464, 466, 468, 470, 472, 474, 476, 478, 480, 482, 484, 486, 488, 490, 492, 494, 496, 498, 500, 502, 504, 506, 508, 510, 512, 514, 516, 518, 520, 522, 524, 526, 528, 530, 532, 534, 536, 538, 540, 542, 544, 546, 548, 550, 552, 554, 556, 558, 560, 562, 564, 566, 568, 570, 572, 574, 576, 578, 580, 582, 584, 586, 588, 590, 592, 594, 596, 598, 600, 602, 604, 606, 608, 610, 612, 614, 616, 618, 620, 622, 624, 626, 628, 630, 632, 634, 636, 638, 640, 642, 644, 646, 648, 650, 652, 654, 656, 658, 660, 662, 664, 666, 668, 670, 672, 674, 676, 678, 680, 682, 684, 686, 688, 690, 692, 694, 696, 698, 700, 702, 704, 706, 708, 710, 712, 714, 716, 718, 720, 722, 724, 726, 728, 730, 732, 734, 736, 738, 740, 742, 744, 746, 748, 750, 752, 754, 756, 758, 760, 762, 764, 766, 768, 770, 772, 774, 776, 778, 780, 782, 784, 786, 788, 790, 792, 794, 796, 798, 800, 802, 804, 806, 808, 810, 812, 814, 816, 818, 820, 822, 824, 826, 828, 830, 832, 834, 836, 838, 840, 842, 844, 846, 848, 850, 852, 854, 856, 858, 860, 862, 864, 866, 868, 870, 872, 874, 876, 878, 880, 882, 884, 886, 888, 890, 892, 894, 896, 898, 900, 902, 904, 906, 908, 910, 912, 914, 916, 918, 920, 922, 924, 926, 928, 930, 932, 934, 936, 938, 940, 942, 944, 946, 948, 950, 952, 954, 956, 958, 960, 962, 964, 966, 968, 970, 972, 974, 976, 978, 980, 982, 984, 986, 988, 990, 992, 994, 996, 998, 1000, 1002, 1004, 1006, 1008, 1010, 1012, 1014, 1016, 1018, 1020, 1022, 1024, 1026, 1028, 1030, 1032, 1034, 1036, 1038, 1040, 1042, 1044, 1046, 1048, 1050, 1052, 1054, 1056, 1058, 1060, 1062, 1064, 1066, 1068, 1070, 1072, 1074, 1076, 1078, 1080, 1082, 1084, 1086, 1088, 1090, 1092, 1094, 1096, 1098, 1100, 1102, 1104, 1106, 1108, 1110, 1112, 1114, 1116, 1118, 1120, 1122, 1124, 1126, 1128, 1130, 1132, 1134, 1136, 1138, 1140, 1142, 1144, 1146, 1148, 1150, 1152, 1154, 1156, 1158, 1160, 1162, 1164, 1166, 1168, 1170, 1172, 1174, 1176, 1178, 1180, 1182, 1184, 1186, 1188, 1190, 1192, 1194, 1196, 1198, 1200, 1202, 1204, 1206, 1208, 1210, 1212, 1214, 1216, 1218, 1220, 1222, 1224, 1226, 1228, 1230, 1232, 1234, 1236, 1238, 1240, 1242, 1244, 1246, 1248, 1250, 1252, 1254, 1256, 1258, 1260, 1262, 1264, 1266, 1268, 1270, 1272, 1274, 1276, 1278, 1280, 1282, 1284, 1286, 1288, 1290, 1292, 1294, 1296, 1298, 1300, 1302, 1304, 1306, 1308, 1310, 1312, 1314, 1316, 1318, 1320, 1322, 1324, 1326, 1328, 1330, 1332, 1334, 1336, 1338, 1340, 1342, 1344, 1346, 1348, 1350, 1352, 1354, 1356, 1358, 1360, 1362, 1364, 1366, 1368, 1370, 1372, 1374, 1376, 1378, 1380, 1382, 1384, 1386, 1388, 1390, 1392, 1394, 1396, 1398, 1400, 1402, 1404, 1406, 1408, 1410, 1412, 1414, 1416, 1418, 1420, 1422, 1424, 1426, 1428, 1430, 1432, 1434, 1436, 1438, 1440, 1442, 1444, 1446, 1448, 1450, 1452, 1454, 1456, 1458, 1460, 1462, 1464, 1466, 1468, 1470, 1472, 1474, 1476, 1478, 1480, 1482, 1484, 1486, 1488, 1490, 1492, 1494, 1496, 1498, 1500, 1502, 1504, 1506, 1508, 1510, 1512, 1514, 1516, 1518, 1520, 1522, 1524, 1526, 1528, 1530, 1532, 1534, 1536, 1538, 1540, 1542, 1544, 1546, 1548, 1550, 1552, 1554, 1556, 1558, 1560, 1562, 1564, 1566, 1568, 1570, 1572, 1574, 1576, 1578, 1580, 1582, 1584, 1586, 1588, 1590, 1592, 1594, 1596, 1598, 1600, 1602, 1604, 1606, 1608, 1610, 1612, 1614, 1616, 1618, 1620, 1622, 1624, 1626, 1628, 1630, 1632, 1634, 1636, 1638, 1640, 1642, 1644, 1646, 1648, 1650, 1652, 1654, 1656, 1658, 1660, 1662, 1664, 1666, 1668, 1670, 1672, 1674, 1676, 1678, 1680, 1682, 1684, 1686, 1688, 1690, 1692, 1694, 1696, 1698, 1700, 1702, 1704, 1706, 1708, 1710, 1712, 1714, 1716, 1718, 1720, 1722, 1724, 1726, 1728, 1730, 1732, 1734, 1736, 1738, 1740, 1742, 1744, 1746, 1748, 1750, 1752, 1754, 1756, 1758, 1760, 1762, 1764, 1766, 1768, 1770, 1772, 1774, 1776, 1778, 1780, 1782, 1784, 1786, 1788, 1790, 1792, 1794, 1796, 1798, 1800, 1802, 1804, 1806, 1808, 1810, 1812, 1814, 1816, 1818, 1820, 1822, 1824, 1826, 1828, 1830, 1832, 1834, 1836, 1838, 1840, 1842, 1844, 1846, 1848, 1850, 1852, 1854, 1856, 1858, 1860, 1862, 1864, 1866, 1868, 1870, 1872, 1874, 1876, 1878, 1880, 1882, 1884, 1886, 1888, 1890, 1892, 1894, 1896, 1898, 1900, 1902, 1904, 1906, 1908, 1910, 1912, 1914, 1916, 1918, 1920, 1922, 1924, 1926, 1928, 1930, 1932, 1934, 1936, 1938, 1940, 1942, 1944, 1946, 1948, 1950, 1952, 1954, 1956, 1958, 1960, 1962, 1964, 1966, 1968, 1970, 1972, 1974, 1976, 1978, 1980, 1982, 1984, 1986, 1988, 1990, 1992, 1994, 1996, 1998]\n",
      "999000\n"
     ]
    }
   ],
   "source": [
    "numbers = range(1000)\n",
    "\n",
    "def mapper(value):\n",
    "    return value*2\n",
    "\n",
    "def reducer(*args):\n",
    "    # print args\n",
    "    return sum(args)\n",
    "\n",
    "# qui calcoliamo il doppio:\n",
    "map_result = map(mapper, numbers)\n",
    "print map_result\n",
    "\n",
    "# qui riduco la lista:\n",
    "result = reduce(reducer, map_result)\n",
    "print result\n",
    "\n",
    "\n",
    "#result = reduce(reducer, map(mapper, numbers))\n",
    "#print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il precedente esempio in \"pure python\" funziona ma ovviamente non efficiente siccome non permette una delle funzionalità core di MapReduce: **working parallely**.\n",
    "\n",
    "Si può facilmente dedurre che ogni **mapper** e **reducer** lavorano su un subset dei dati e sono completamente indipendenti dallo status degli altri mapper e reducer. Quindi il processo può procedere in parallelo senza intoppi.\n",
    "\n",
    "## Parallel Map Reduce in Pure Python\n",
    "\n",
    "Ecco un esempio di simulazione di un processo map reduce in parallelo in python utilizzando il modulo **multiprocessing**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import multiprocessing\n",
    "\n",
    "class ParallelMapReduce(object):\n",
    "    # __init__ definisce una funzione\n",
    "    def __init__(self, map_func, reduce_func, num_workers=None):\n",
    "        self.num_workers = num_workers\n",
    "        self.map_func = map_func\n",
    "        self.reduce_func = reduce_func\n",
    "        self.pool = multiprocessing.Pool(num_workers)\n",
    "    \n",
    "    def partition(self, n, iterable):\n",
    "        i = iter(iterable)\n",
    "        piece = list(islice(i, n))\n",
    "        # print \"partizione 1: \", piece\n",
    "        while piece:\n",
    "            # print \"--> \", piece\n",
    "            yield piece\n",
    "            piece = list(islice(i, n))\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        values = self.pool.map(self.map_func, inputs)\n",
    "        \n",
    "        print '>>> MAPPED VALUES (%s values): %s, ...' % (len(values), str(values[:10]))\n",
    "\n",
    "        values = self.pool.map(self.reduce_func, \n",
    "                               self.partition(len(values)//self.num_workers, values))\n",
    "        print '>>> REDUCED VALUES', values\n",
    "\n",
    "        return self.reduce_func(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'esempio crea **N** partizioni in base a quanti **N** workers sono stati dichiarati, a questo punto ogni worker riceve i vari input e restituisce il risultato di ogni singolo step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> MAPPED VALUES (1000 values): [0, 2, 4, 6, 8, 10, 12, 14, 16, 18], ...\n",
      ">>> REDUCED VALUES [9900, 29900, 49900, 69900, 89900, 109900, 129900, 149900, 169900, 189900]\n",
      ">>> RESULT: 999000\n"
     ]
    }
   ],
   "source": [
    "numbers = range(1000)\n",
    "\n",
    "def mapper(value):\n",
    "    return value*2\n",
    "\n",
    "def reducer(values):\n",
    "    return sum(values)\n",
    "\n",
    "mapreduce = ParallelMapReduce(mapper, reducer, 10) # 10 è il num dei workers\n",
    "print \">>> RESULT: %s\" % mapreduce(numbers) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File System\n",
    "\n",
    "Un **file system** (abbreviazione: FS) indica informalmente un meccanismo con il quale i file sono posizionati e organizzati o su un dispositivo di archiviazione o su una memoria di massa, come un disco rigido o un CD-ROM e, in casi eccezionali, anche sulla RAM.\n",
    "\n",
    "[Definizione su WIKIPEDIA](https://it.wikipedia.org/wiki/File_system)\n",
    "\n",
    "### File System Distribuito\n",
    "\n",
    "Un **file system distribuito** (in inglese, Distributed File System, o DFS) è un particolare file system che permette la memorizzazione di files e risorse in dispositivi di archiviazione distribuiti in una rete informatica, anziché letti o archiviati in maniera centralizzata su di un dispositivo locale, e resi dunque disponibili attraverso un meccanismo client-server tra dispositivi remoti.\n",
    "\n",
    "[Definizione su WIKIPEDIA](https://it.wikipedia.org/wiki/File_system_distribuito)\n",
    "\n",
    "## Distributed Map Reduce\n",
    "\n",
    "Il nostro esempio di map reduce lavora in parallelo usando i core multipli del nostro computer, non è però in grado di distribuire il lavoro su computer differenti. Siccome MapReduce nasce per poter eseguire lo stesso processo in un ambiente distribuito è di vitale importanza riuscire a creare un codice che lavori attraverso molteplici server in parallelo.\n",
    "\n",
    "Questa è la ragione per cui sono stati creati differenti framework per MapReduce, ecco alcune soluzioni per python:\n",
    "\n",
    "\n",
    "### Disco ###\n",
    "\n",
    "Progetto nato al centro di ricerca Nokia, è una delle soluzioni con un ottimo tradeof fra complessità e funzionalità. Python è considerato il linguaggio standard per implementare logiche mapReduce attraverso i workers messi a  disposizione dal **job dispatcher**.\n",
    "\n",
    "Fornisce inoltre un suo Distributed File System (DDFS) e Distributed Database (DiscoDB) che può essere utilizzato per salvare dati attraverso i vari workers.\n",
    "\n",
    "### OctoPy ###\n",
    "\n",
    "Soluzione \"pure Python\" semplice e rapida da implementare ma non fornisce disco condiviso per i dati. Può essere una buona soluzione per problemi di piccola dimensione dove il costo della configurazione del cluster ridotto può essere un buon benefit.\n",
    "\n",
    "### Hadoop ###\n",
    "\n",
    "Hadoop è lo standard de facto in frameworks MapReduce, implementato in Java rappresenta la soluzione più complessa per setup e mantenimento. Tramite l'**Hadoop Streaming** è possibile eseguire mappers e reducers in qualsiasi linguaggio di programmazione che può essere chiamato da uno script shell. Hadoop Streaming è usato da diverse librerie Python che permettono l'implementazione di soluzioni MapReduce in facilità.\n",
    "\n",
    "Come Disco fornisce una soluzione a 360 gradi fornendo un Distributed File System **HDFS** dove i dati possono essere salvati durante l'esecuzione degli script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon EMR - Elastic MapReduce\n",
    "\n",
    "\n",
    "EMR, **Elastic Map Reduce** è la soluzione Amazon per cluster Hadoop in cloud.\n",
    "\n",
    "Creare e gestire un cluster Hadoop è un processo lungo e complesso, è buona norma utilizzare servizi di cloud computing on demand. Durante le lezioni vedremo come utilizzare script MapReduce in locale, ma vedremo anche come utilizzare ERM per eseguire gli stessi script. Noteremo che EMR ha alti costi di kickstart, di conseguenza andrà utilizzato solo quando la mole di dati è molto elevata.\n",
    "\n",
    "Il tutto funziona su Amazon **Elastic Compute Cloud** (EC2) per la creazione di instanze ad hoc collegate fra di loro per la creazione del cluster Hadoop. Sfrutta inoltre **Simple Storage Service** (S3) per la gestione di file system condiviso, ogni nodo potrà accedere e scaricare / uploadare dati.\n",
    "\n",
    "<img src=\"files/ec2.png\" width=\"640\"/>\n",
    "\n",
    "### Costo di Setup (Kickstart cost)\n",
    "\n",
    "Il problema nell'utilizzo di EMR è nell'elevato costo di avvio / setup causato da:\n",
    "\n",
    " - Le istanza EC2 necessitano di essere create e accese per cominciare a processare dati\n",
    " - I dati necessitano di essere caricati su un bucket di S3 per permettere alle istanze di accedervi e di iniziare il lavoro\n",
    " \n",
    "Per queste ragioni, siccome l'avvio necessita di attendere minuti, sarà più comodo in fase di esercizio / learning eseguire gli script in locale tramite un framework multiprocess che simula i nodi Hadoop. Vedremo però come sarà possibile utilizzare gli stessi script senza la necessità di effettuare modifiche per eseguirli in ambiente distribuito direttamente su Amazon EMR.\n",
    "\n",
    "\n",
    "# Hadoop Streaming\n",
    "\n",
    "La funzionalità che permette di eseguire algoritmi MapReduce in un qualsiasi linguaggio su Hadoop è chiamata Hadoop Streaming, è un tool che riceve come parametro di input un qualsiasi software eseguibile da linea di comando costituito da un mapper e un reducer.\n",
    "\n",
    "Questo rende possibile l'utilizzo di uno script Python all'interno del cluster Hadoop che dovrà utilizzare il protocollo per la gestione di input e output (i dati saranno separati da un \"\\n\"):\n",
    "\n",
    " - Ogni \"linea\" di input inviata al mapper si deve considerare come un singolo valore da mappare\n",
    " - Ogni \"linea\" di output restituita dal mapper è da considerare come una tupla (key, value) dove key e value sono rispettivamente reparate da un TAB (\"\\t\")\n",
    " \n",
    "Ecco un esempio di classico I/O di uno Streaming Hadoop:\n",
    "\n",
    "`key1\\tvalue1\\nkey2\\tvalue2\\n`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  DEMO\n",
    "\n",
    "## Trovare film simili sulla base del Rating degli utenti - Movie recommendation\n",
    "\n",
    "Utilizzando un dataset di voti raccolti da utenti anonimi (fonte del dataset: MovieLands), seguiamo i seguenti step:\n",
    "\n",
    "- Troviamo tutte le coppie di film visti dalle stesse persone\n",
    "- Calcoliamo la *similarity* basato sul rating degli utenti che hanno visto entrambi\n",
    "- Ordiniamo per film utilizzando il livello di *similarity*\n",
    "    \n",
    "\n",
    "### MapReduce Problem\n",
    "\n",
    "MapReduce problem, 3 steps (tempo di calcolo circa --> XX per dataset da 100K entries):\n",
    "\n",
    "    Mapper: Estraggo tutti gli utenti e i film visti con associato il rating dato -> (Movie, Rating)\n",
    "    Reducer: Raggruppo per utente tutti i film visti con associato per ognuno il rating\n",
    "\n",
    "    Mapper: Restituisco tutti i film visti da ogni utente con il rating (movie1, movie2) ->  (rating1, rating2)\n",
    "    Reducer: Calcolo la rating-based similarity per ogni coppia di film (movie1, movie2) -> (similarity, numero di utenti che ha visto entrambi)\n",
    "\n",
    "    Mapper: Recupero il nome del film e la sua similarity\n",
    "    Reducer: Restituisco l'output\n",
    "    \n",
    "    Output: -> Lista di film in ordine per nome con lista di film correlati in base al grado di similarity\n",
    "    Format:  \"MOVIE_NAME\" [\"SIMILAR_MOVIE\", \"SIMILAR_POINT (From 0 to 1)\", \"Number of people who votes both\"]\n",
    "    Example: \"Start Wars 1977\" [\"Empire Strikes Back 1980\", 0.989552207, 345]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Risultato su Star Wars 1977\n",
    "\n",
    "    GRADO DI SIMILARITY [ FILM_NAME, Numero di voti da parte di utenti]\n",
    "    0.9895522078385338\t[\"Empire Strikes Back, The (1980)\", 345]\n",
    "    0.9857230861253026\t[\"Return of the Jedi (1983)\", 480]\n",
    "    0.9817600988726190\t[\"Raiders of the Lost Ark (1981)\", 380]    \n",
    "    0.9735394829992481\t[\"Indiana Jones and the Last Crusade (1989)\", 304]    \n",
    "    0.9672204017083984\t[\"Toy Story (1995)\", 381]    \n",
    "    0.9672159797078707\t[\"Back to the Future (1985)\", 309]\n",
    "    0.9669998681287573\t[\"Star Trek: First Contact (1996)\", 316]\n",
    "    0.9647806324397128\t[\"Godfather, The (1972)\", 357]\n",
    "    0.9644359422817009\t[\"Silence of the Lambs, The (1991)\", 335]\n",
    "    0.9595898029305344\t[\"Contact (1997)\", 334]\n",
    "    0.9568016154365081\t[\"Twelve Monkeys (1995)\", 324]    \n",
    "    0.9546838657901240\t[\"Fargo (1996)\", 394]\n",
    "    0.9522886451418612\t[\"Rock, The (1996)\", 312]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Come eseguire la DEMO\n",
    "\n",
    "Prima di tutto assicurarsi di avere MrJob installato (verrà spiegato nel capitolo 5).\n",
    "\n",
    "Sarà sufficiente eseguire lo script contenuto nel file **script.py**:\n",
    "\n",
    "    python script.py --items=u.item u.data > result_file\n",
    "    \n",
    "Dopo un paio di minuti (la velocità dipende dal vostro PC) il risultato verrà stampato nel file **result_file**.\n",
    "\n",
    "Successivamente si può applicare il secondo script per filtrare sul file dei risultati:\n",
    "\n",
    "    python clean.py result_file\n",
    "    \n",
    "Per cercare uno specifico film sarà sufficiente cambiare il nome del film ricercato nel file **clean.py** in riga 8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
