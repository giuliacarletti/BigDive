{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"http://www.bigdive.eu/wp-content/uploads/2012/05/logoBIGDIVE-01.png\">\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "# Text Analysis\n",
    "\n",
    "## André Panisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "### The 20 Newsgroups data set\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups\n",
    "\n",
    "The data is organized into 20 different newsgroups, each corresponding to a different topic. Some of the newsgroups are very closely related to each other (e.g. comp.sys.ibm.pc.hardware / comp.sys.mac.hardware), while others are highly unrelated (e.g misc.forsale / soc.religion.christian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dataset = datasets.fetch_20newsgroups()\n",
    "documents = dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Removing from text pieces that do not convey any semantic meaning (e.g., mail headers, email adresses, host names...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re   # questa regular expression serve per rimuovere il prompt; elimina la riga con il From:\n",
    "from_re = re.compile(r\"^From: .*\\n\")   # . vuol dire qualunque carattere\n",
    "\n",
    "print from_re.sub('', documents[0])  # sub sta per substitution; cioè sostituisce questo con una stringa vuota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(documents)):     # serve per sostituire su tutti i documenti\n",
    "    documents[i] = from_re.sub('', documents[i])\n",
    "print documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: create a regular expression to remove the Nntp-Posting-Host header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: WHAT car is this!?\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re  \n",
    "Nntp_re = re.compile(r\"\\nNntp-Posting-Host: .*\\n\")\n",
    "\n",
    "print Nntp_re.sub('\\n', documents[0])   # sostituisco per la new line; al posto di '', metto '\\n', \n",
    "# così non mi mette tutte le linee allo stesso livello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re  \n",
    "Nntp_re = re.compile(r\"\\nNntp-Posting-Host: .*\\n\")\n",
    "\n",
    "print Nntp_re.sub('\\n', documents[1])   # nel documento 1 ho ancora la riga con NNTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re  \n",
    "nntp_re = re.compile(r\"\\nNntp-Posting-Host: .*\\n\", flags = re.IGNORECASE)  # così è più generale, \n",
    "# toglie tutte le righe con NNTP sia maiuscolo che minuscolo\n",
    "\n",
    "print nntp_re.sub('\\n', documents[1])   # nel documento 1 non ho più la riga con NNTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: WHAT car is this!?Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(documents)):     # serve per sostituire su tutti i documenti\n",
    "    documents[i] = Nntp_re.sub('\\n', documents[i])\n",
    "print documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Text Messages to Feature Vectors\n",
    "We need to transform our text data into feature vectors, numerical representations which are suitable for performing statistical analysis. The most common way to do this is to apply a bag-of-words approach where the frequency of an occurrence of a word becomes a feature for our classifier.\n",
    "\n",
    "\n",
    "## Term Frequency-Inverse Document Frequency\n",
    "\n",
    "We want to consider the relative importance of particular words, so we'll use term frequency–inverse document frequency as a weighting factor. This will control for the fact that some words are more \"spamy\" than others.\n",
    "\n",
    "## Mathematical details\n",
    "\n",
    "tf–idf is the product of two statistics, term frequency and inverse document\n",
    "frequency. Various ways for determining the exact values of both statistics\n",
    "exist. In the case of the '''term frequency''' tf(''t'',''d''), the simplest\n",
    "choice is to use the ''raw frequency'' of a term in a document, i.e. the\n",
    "number of times that term ''t'' occurs in document ''d''. If we denote the raw\n",
    "frequency of ''t'' by f(''t'',''d''), then the simple tf scheme is\n",
    "tf(''t'',''d'') = f(''t'',''d''). Other possibilities\n",
    "include:\n",
    "\n",
    "  * boolean_data_type \"frequencies\": tf(''t'',''d'') = 1 if ''t'' occurs in ''d'' and 0 otherwise; \n",
    "  * logarithmically scaled frequency: tf(''t'',''d'') = log (f(''t'',''d'') + 1); \n",
    "  * augmented frequency, to prevent a bias towards longer documents, e.g. raw frequency divided by the maximum raw frequency of any term in the document: :$\\mathrm{tf}(t,d) = 0.5 + \\frac{0.5 \\times \\mathrm{f}(t, d)}{\\max\\{\\mathrm{f}(w, d):w \\in d\\}}$\n",
    "\n",
    "The '''inverse document frequency''' is a measure of whether the term is\n",
    "common or rare across all documents. It is obtained by dividing the total\n",
    "number of documents by the number of documents containing the\n",
    "term, and then taking the logarithm of that quotient.\n",
    "\n",
    ":$ \\mathrm{idf}(t, D) = \\log \\frac{|D|}{|\\{d \\in D: t \\in d\\}|}$\n",
    "\n",
    "with\n",
    "\n",
    "  * $ |D| $: cardinality of D, or the total number of documents in the corpus \n",
    "  * $ |\\{d \\in D: t \\in d\\}| $ : number of documents where the term $ t $ appears (i.e., $ \\mathrm{tf}(t,d) eq 0$). If the term is not in the corpus, this will lead to a division-by-zero. It is therefore common to adjust the formula to $1 + |\\{d \\in D: t \\in d\\}|$. \n",
    "\n",
    "Mathematically the base of the log function does not matter and constitutes a\n",
    "constant multiplicative factor towards the overall result.\n",
    "\n",
    "Then tf–idf is calculated as\n",
    "\n",
    "$$\\mathrm{tfidf}(t,d,D) = \\mathrm{tf}(t,d) \\times \\mathrm{idf}(t, D)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# l'idea è dare meno peso a parole che appaiono di più nel documento\n",
    "# prendo la frequenza del termine e la divido per la document frequency\n",
    "# se la parola appare in tutti i doc ho document frequency = n, e la inverse document frequency = 1/n\n",
    "# posso usare il log se il numero di parole è molto alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset(['all', 'six', 'less', 'being', 'indeed', 'over', 'move', 'anyway', 'four', 'not', 'own', 'through', 'yourselves', 'fify', 'where', 'mill', 'only', 'find', 'before', 'one', 'whose', 'system', 'how', 'somewhere', 'with', 'thick', 'show', 'had', 'enough', 'should', 'to', 'must', 'whom', 'seeming', 'under', 'ours', 'has', 'might', 'thereafter', 'latterly', 'do', 'them', 'his', 'around', 'than', 'get', 'very', 'de', 'none', 'cannot', 'every', 'whether', 'they', 'front', 'during', 'thus', 'now', 'him', 'nor', 'name', 'several', 'hereafter', 'always', 'who', 'cry', 'whither', 'this', 'someone', 'either', 'each', 'become', 'thereupon', 'sometime', 'side', 'two', 'therein', 'twelve', 'because', 'often', 'ten', 'our', 'eg', 'some', 'back', 'up', 'go', 'namely', 'towards', 'are', 'further', 'beyond', 'ourselves', 'yet', 'out', 'even', 'will', 'what', 'still', 'for', 'bottom', 'mine', 'since', 'please', 'forty', 'per', 'its', 'everything', 'behind', 'un', 'above', 'between', 'it', 'neither', 'seemed', 'ever', 'across', 'she', 'somehow', 'be', 'we', 'full', 'never', 'sixty', 'however', 'here', 'otherwise', 'were', 'whereupon', 'nowhere', 'although', 'found', 'alone', 're', 'along', 'fifteen', 'by', 'both', 'about', 'last', 'would', 'anything', 'via', 'many', 'could', 'thence', 'put', 'against', 'keep', 'etc', 'amount', 'became', 'ltd', 'hence', 'onto', 'or', 'con', 'among', 'already', 'co', 'afterwards', 'formerly', 'within', 'seems', 'into', 'others', 'while', 'whatever', 'except', 'down', 'hers', 'everyone', 'done', 'least', 'another', 'whoever', 'moreover', 'couldnt', 'throughout', 'anyhow', 'yourself', 'three', 'from', 'her', 'few', 'together', 'top', 'there', 'due', 'been', 'next', 'anyone', 'eleven', 'much', 'call', 'therefore', 'interest', 'then', 'thru', 'themselves', 'hundred', 'was', 'sincere', 'empty', 'more', 'himself', 'elsewhere', 'mostly', 'on', 'fire', 'am', 'becoming', 'hereby', 'amongst', 'else', 'part', 'everywhere', 'too', 'herself', 'former', 'those', 'he', 'me', 'myself', 'made', 'twenty', 'these', 'bill', 'cant', 'us', 'until', 'besides', 'nevertheless', 'below', 'anywhere', 'nine', 'can', 'of', 'your', 'toward', 'my', 'something', 'and', 'whereafter', 'whenever', 'give', 'almost', 'wherever', 'is', 'describe', 'beforehand', 'herein', 'an', 'as', 'itself', 'at', 'have', 'in', 'seem', 'whence', 'ie', 'any', 'fill', 'again', 'hasnt', 'inc', 'thereby', 'thin', 'no', 'perhaps', 'latter', 'meanwhile', 'when', 'detail', 'same', 'wherein', 'beside', 'also', 'that', 'other', 'take', 'which', 'becomes', 'you', 'if', 'nobody', 'see', 'though', 'may', 'after', 'upon', 'most', 'hereupon', 'eight', 'but', 'serious', 'nothing', 'such', 'why', 'a', 'off', 'whereby', 'third', 'i', 'whole', 'noone', 'sometimes', 'well', 'amoungst', 'yours', 'their', 'rather', 'without', 'so', 'five', 'the', 'first', 'whereas', 'once'])\n"
     ]
    }
   ],
   "source": [
    "stop_words=text.ENGLISH_STOP_WORDS  # sono le parole che vengono rimosse a priori\n",
    "print stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = text.CountVectorizer(max_df=0.8, max_features=10000, stop_words=text.ENGLISH_STOP_WORDS)\n",
    "# non voglio le parole che appaiono più dell'80% di volte (max_df)\n",
    "# max_featues: mi fermo alle prime 10.000 parole\n",
    "\n",
    "counts = vectorizer.fit_transform(documents)  #trasformo i documents (sono i dati già modificati, non gli originali)\n",
    "tfidf = text.TfidfTransformer().fit_transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x10000 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 961148 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts\n",
    "# ho una matrice sparsa da 11314 x 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10000 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[0]  # nella prima parola ho 45 conteggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x10000 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 961148 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x10000 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[0]   # ho 45 documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18656586,  0.13263726,  0.14025822,  0.0781466 ,  0.08505631,\n",
       "        0.09796541,  0.10370348,  0.11829885,  0.15352379,  0.08596117,\n",
       "        0.15377648,  0.13775353,  0.12541194,  0.06070968,  0.12359746,\n",
       "        0.1158666 ,  0.13995128,  0.18831898,  0.13520295,  0.10671771,\n",
       "        0.08035095,  0.16453782,  0.09796541,  0.19674401,  0.11985554,\n",
       "        0.13072431,  0.12813531,  0.15327343,  0.14201133,  0.09411946,\n",
       "        0.12000159,  0.1901931 ,  0.12595344,  0.08979532,  0.14072523,\n",
       "        0.11062217,  0.15507644,  0.05258733,  0.04132957,  0.1508891 ,\n",
       "        0.18413164,  0.05022631,  0.04887988,  0.05058214,  0.54073254])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'woods': 9800,\n",
       " u'hanging': 4312,\n",
       " u'broward': 1735,\n",
       " u'bringing': 1719,\n",
       " u'wednesday': 9691,\n",
       " u'shows': 8189,\n",
       " u'cfa': 2012,\n",
       " u'frederick': 3938,\n",
       " u'270': 309,\n",
       " u'272': 310,\n",
       " u'273': 311,\n",
       " u'274': 312,\n",
       " u'275': 313,\n",
       " u'278': 314,\n",
       " u'targa': 8815,\n",
       " u'errors': 3477,\n",
       " u'usenet': 9373,\n",
       " u'designing': 2947,\n",
       " u'kids': 5155,\n",
       " u'controversy': 2508,\n",
       " u'dna': 3120,\n",
       " u'inevitable': 4732,\n",
       " u'benedikt': 1499,\n",
       " u'intake': 4827,\n",
       " u'morally': 6000,\n",
       " u'wang': 9632,\n",
       " u'want': 9634,\n",
       " u'beyer': 1518,\n",
       " u'travel': 9115,\n",
       " u'wrong': 9845,\n",
       " u'slightest': 8287,\n",
       " u'fit': 3809,\n",
       " u'wiretapping': 9765,\n",
       " u'fix': 3812,\n",
       " u'fij': 3771,\n",
       " u'effects': 3323,\n",
       " u'sheep': 8150,\n",
       " u'6ql': 568,\n",
       " u'estimate': 3502,\n",
       " u'sys': 8771,\n",
       " u'needed': 6171,\n",
       " u'master': 5714,\n",
       " u'genesis': 4065,\n",
       " u'0d': 20,\n",
       " u'ahmet': 908,\n",
       " u'feeling': 3740,\n",
       " u'affairs': 872,\n",
       " u'vga': 9505,\n",
       " u'sy_': 8755,\n",
       " u'tech': 8845,\n",
       " u'saying': 7923,\n",
       " u'chelios': 2065,\n",
       " u'plate': 6858,\n",
       " u'altogether': 981,\n",
       " u'nicely': 6226,\n",
       " u'patch': 6670,\n",
       " u'widget': 9728,\n",
       " u'news': 6208,\n",
       " u'lots': 5530,\n",
       " u'irq': 4922,\n",
       " u'irs': 4925,\n",
       " u'extend': 3626,\n",
       " u'nature': 6137,\n",
       " u'extent': 3631,\n",
       " u'fri': 3955,\n",
       " u'bothers': 1659,\n",
       " u'doubts': 3167,\n",
       " u'spin': 8432,\n",
       " u'memorial': 5809,\n",
       " u'udel': 9243,\n",
       " u'zeos': 9979,\n",
       " u'academic': 751,\n",
       " u'corporate': 2557,\n",
       " u'hal': 4284,\n",
       " u'ham': 4290,\n",
       " u'har': 4322,\n",
       " u'hat': 4345,\n",
       " u'crowd': 2652,\n",
       " u'czech': 2732,\n",
       " u'liver': 5466,\n",
       " u'mangoe': 5650,\n",
       " u'raped': 7370,\n",
       " u'toolkits': 9045,\n",
       " u'mirror': 5911,\n",
       " u'pasadena': 6654,\n",
       " u'omran': 6433,\n",
       " u'corps': 2560,\n",
       " u'chair': 2015,\n",
       " u'jerk': 4999,\n",
       " u'exact': 3538,\n",
       " u'minute': 5906,\n",
       " u'ground': 4225,\n",
       " u'address': 830,\n",
       " u'raise': 7348,\n",
       " u'opposed': 6469,\n",
       " u'oscillator': 6517,\n",
       " u'following': 3860,\n",
       " u'significant': 8211,\n",
       " u'agricultural': 903,\n",
       " u'dcs': 2799,\n",
       " u'pettefar': 6755,\n",
       " u'jim': 5013,\n",
       " u'didn': 3007,\n",
       " u'quarter': 7284,\n",
       " u'entering': 3436,\n",
       " u'seriously': 8090,\n",
       " u'byte': 1813,\n",
       " u'spoken': 8439,\n",
       " u'turned': 9192,\n",
       " u'turner': 9193,\n",
       " u'zoo': 9991,\n",
       " u'opposite': 6471,\n",
       " u'messier': 5831,\n",
       " u'lindros': 5432,\n",
       " u'yuma': 9963,\n",
       " u'838': 630,\n",
       " u'mpg': 6050,\n",
       " u'west': 9708,\n",
       " u'motives': 6021,\n",
       " u'photos': 6784,\n",
       " u'technology': 8855,\n",
       " u'verified': 9489,\n",
       " u'cunyvm': 2696,\n",
       " u'otto': 6526,\n",
       " u'generator': 4061,\n",
       " u'excuses': 3562,\n",
       " u'traffic': 9088,\n",
       " u'preference': 7008,\n",
       " u'satisfactory': 7909,\n",
       " u'substance': 8639,\n",
       " u'hopkins': 4501,\n",
       " u'37': 389,\n",
       " u'sealed': 7992,\n",
       " u'punished': 7225,\n",
       " u'allan': 957,\n",
       " u'abused': 746,\n",
       " u'rage': 7342,\n",
       " u'dirty': 3044,\n",
       " u'abuses': 747,\n",
       " u'trips': 9146,\n",
       " u'watched': 9662,\n",
       " u'nrhj': 6295,\n",
       " u'waving': 9672,\n",
       " u'tricky': 9137,\n",
       " u'caused': 1955,\n",
       " u'beware': 1517,\n",
       " u'causes': 1956,\n",
       " u'riots': 7711,\n",
       " u'norm': 6265,\n",
       " u'24x': 292,\n",
       " u'sank': 7898,\n",
       " u'199': 188,\n",
       " u'198': 177,\n",
       " u'195': 158,\n",
       " u'196': 161,\n",
       " u'190': 147,\n",
       " u'192': 153,\n",
       " u'slmr': 8290,\n",
       " u'hasn': 4343,\n",
       " u'hash': 4342,\n",
       " u'skepticism': 8261,\n",
       " u'vlsi': 9555,\n",
       " u'odometer': 6388,\n",
       " u'initiated': 4776,\n",
       " u'company': 2310,\n",
       " u'corrected': 2563,\n",
       " u'installing': 4808,\n",
       " u'learn': 5327,\n",
       " u'knocked': 5191,\n",
       " u'uxa': 9425,\n",
       " u'huge': 4540,\n",
       " u'brett': 1707,\n",
       " u'media': 5785,\n",
       " u'installed': 4807,\n",
       " u'paper': 6615,\n",
       " u'scott': 7965,\n",
       " u'everytime': 3531,\n",
       " u'random': 7360,\n",
       " u'courses': 2593,\n",
       " u'research': 7601,\n",
       " u'bye': 1811,\n",
       " u'saint': 7876,\n",
       " u'wording': 9803,\n",
       " u'3p': 412,\n",
       " u'3t': 415,\n",
       " u'3n': 410,\n",
       " u'secular': 8020,\n",
       " u'3e': 404,\n",
       " u'insane': 4793,\n",
       " u'312': 362,\n",
       " u'310': 361,\n",
       " u'316': 365,\n",
       " u'314': 364,\n",
       " u'analog': 1012,\n",
       " u'fx': 3999,\n",
       " u'struct': 8605,\n",
       " u'objects': 6350,\n",
       " u'bell': 1490,\n",
       " u'luis': 5556,\n",
       " u'belt': 1495,\n",
       " u'geoffrey': 4075,\n",
       " u'nrl': 6297,\n",
       " u'nra': 6293,\n",
       " u'1f9': 222,\n",
       " u'budget': 1755,\n",
       " u'pressed': 7032,\n",
       " u'005': 2,\n",
       " u'binding': 1547,\n",
       " u'sorenson': 8364,\n",
       " u'infamous': 4737,\n",
       " u'manufacturing': 5667,\n",
       " u'hercules': 4409,\n",
       " u'parents': 6628,\n",
       " u'couple': 2590,\n",
       " u'uwaterloo': 9416,\n",
       " u'bounce': 1663,\n",
       " u'committing': 2297,\n",
       " u'behave': 1476,\n",
       " u'assisted': 1217,\n",
       " u'inspector': 4801,\n",
       " u'terrorists': 8907,\n",
       " u'bios': 1553,\n",
       " u'gatech': 4030,\n",
       " u'atlantic': 1251,\n",
       " u'erich': 3473,\n",
       " u'sudbury': 8653,\n",
       " u'uranium': 9357,\n",
       " u'revision': 7671,\n",
       " u'bolshevik': 1626,\n",
       " u'algorithm': 945,\n",
       " u'train': 9091,\n",
       " u'turkish': 9188,\n",
       " u'shutout': 8191,\n",
       " u'video': 9515,\n",
       " u'dynamics': 3256,\n",
       " u'victor': 9512,\n",
       " u'multimedia': 6076,\n",
       " u'obvious': 6366,\n",
       " u'makes': 5633,\n",
       " u'oulu': 6531,\n",
       " u'tclock': 8830,\n",
       " u'home': 4476,\n",
       " u'confidence': 2397,\n",
       " u'nmm': 6247,\n",
       " u'customer': 2710,\n",
       " u'rode': 7755,\n",
       " u'intelligent': 4837,\n",
       " u'mjs': 5940,\n",
       " u'houston': 4525,\n",
       " u'volts': 9570,\n",
       " u'insight': 4796,\n",
       " u'physicians': 6790,\n",
       " u'books': 1638,\n",
       " u'witness': 9777,\n",
       " u'relays': 7520,\n",
       " u't47': 8782,\n",
       " u't45': 8781,\n",
       " u'k8v': 5100,\n",
       " u'interests': 4853,\n",
       " u'enforcement': 3414,\n",
       " u'stomach': 8561,\n",
       " u'gays': 4038,\n",
       " u'false': 3682,\n",
       " u'tonight': 9039,\n",
       " u'fd': 3721,\n",
       " u'cipher': 2118,\n",
       " u'entities': 3442,\n",
       " u'tape': 8811,\n",
       " u'riding': 7700,\n",
       " u'xsun': 9899,\n",
       " u'ira': 4912,\n",
       " u'sinus': 8243,\n",
       " u'taxes': 8826,\n",
       " u'stuff': 8620,\n",
       " u'ohio': 6405,\n",
       " u'guessing': 4247,\n",
       " u'chicogo': 2079,\n",
       " u'frame': 3925,\n",
       " u'simtel20': 8230,\n",
       " u'nuclear': 6309,\n",
       " u'genetic': 4066,\n",
       " u'moved': 6038,\n",
       " u'rbi': 7391,\n",
       " u'greater': 4205,\n",
       " u'moves': 6041,\n",
       " u'baalke': 1359,\n",
       " u'diabetes': 2994,\n",
       " u'storage': 8569,\n",
       " u'oilers': 6408,\n",
       " u'technet': 8847,\n",
       " u'crack': 2614,\n",
       " u'admit': 847,\n",
       " u'cruz': 2658,\n",
       " u'recognition': 7442,\n",
       " u'passion': 6663,\n",
       " u'biology': 1552,\n",
       " u'manta': 5658,\n",
       " u'snyder': 8321,\n",
       " u'evident': 3533,\n",
       " u'problem': 7087,\n",
       " u'details': 2967,\n",
       " u'outlets': 6538,\n",
       " u'exposure': 3621,\n",
       " u'strings': 8597,\n",
       " u'compete': 2326,\n",
       " u'magnetic': 5605,\n",
       " u'integrity': 4832,\n",
       " u'messenger': 5829,\n",
       " u'aurora': 1289,\n",
       " u'cma': 2213,\n",
       " u'destroying': 2961,\n",
       " u'cmu': 2215,\n",
       " u'sabbath': 7861,\n",
       " u'machines': 5591,\n",
       " u'581': 501,\n",
       " u'achieve': 785,\n",
       " u'mathew': 5725,\n",
       " u'championships': 2025,\n",
       " u'1991': 190,\n",
       " u'1990': 189,\n",
       " u'1993': 192,\n",
       " u'1992': 191,\n",
       " u'1995': 211,\n",
       " u'1994': 210,\n",
       " u'ers': 3478,\n",
       " u'era': 3470,\n",
       " u'carriers': 1921,\n",
       " u'nuts': 6318,\n",
       " u'mph': 6051,\n",
       " u'schneider': 7945,\n",
       " u'mps': 6053,\n",
       " u'production': 7105,\n",
       " u'reasonably': 7423,\n",
       " u'routines': 7794,\n",
       " u'reasonable': 7422,\n",
       " u'daniel': 2761,\n",
       " u'disputed': 3089,\n",
       " u'barrier': 1405,\n",
       " u'certified': 2009,\n",
       " u'bontchev': 1634,\n",
       " u'dogs': 3142,\n",
       " u'guild': 4253,\n",
       " u'guilt': 4254,\n",
       " u'historical': 4441,\n",
       " u'contents': 2477,\n",
       " u'convenient': 2510,\n",
       " u'subjects': 8629,\n",
       " u'conscience': 2425,\n",
       " u'aunt': 1288,\n",
       " u'reserve': 7603,\n",
       " u'runs': 7829,\n",
       " u'qazi': 7258,\n",
       " u'cooperation': 2535,\n",
       " u'drawn': 3190,\n",
       " u'answers': 1057,\n",
       " u'kitchen': 5176,\n",
       " u'essentially': 3496,\n",
       " u'tone': 9037,\n",
       " u'tons': 9040,\n",
       " u'tony': 9041,\n",
       " u'gnp': 4132,\n",
       " u'gnv': 4134,\n",
       " u'spending': 8428,\n",
       " u'survival': 8722,\n",
       " u'fuse': 3994,\n",
       " u'humble': 4551,\n",
       " u'client': 2186,\n",
       " u'casbah': 1931,\n",
       " u'newton': 6216,\n",
       " u'thanks': 8925,\n",
       " u'yamaha': 9926,\n",
       " u'usable': 9364,\n",
       " u'y1': 9918,\n",
       " u'designers': 2946,\n",
       " u'precise': 6997,\n",
       " u'night': 6231,\n",
       " u'cirrus': 2129,\n",
       " u'sahak': 7873,\n",
       " u'rendering': 7553,\n",
       " u'b8e': 1352,\n",
       " u'b8g': 1354,\n",
       " u'b8f': 1353,\n",
       " u'postscript': 6961,\n",
       " u'test': 8910,\n",
       " u'concept': 2370,\n",
       " u'y2': 9919,\n",
       " u'battle': 1432,\n",
       " u'dartmouth': 2772,\n",
       " u'turns': 9195,\n",
       " u'gui': 4249,\n",
       " u'gun': 4258,\n",
       " u'gut': 4261,\n",
       " u'guy': 4263,\n",
       " u'shared': 8138,\n",
       " u'staff': 8478,\n",
       " u'vram': 9586,\n",
       " u'teaches': 8838,\n",
       " u'teacher': 8836,\n",
       " u'sending': 8061,\n",
       " u'franklin': 3933,\n",
       " u'f0': 3645,\n",
       " u'regardless': 7486,\n",
       " u'extra': 3635,\n",
       " u'fbi': 3718,\n",
       " u'courtnall': 2596,\n",
       " u'ibm': 4583,\n",
       " u'inferior': 4746,\n",
       " u'chip': 2085,\n",
       " u'discussion': 3073,\n",
       " u'kurt': 5222,\n",
       " u'brain': 1685,\n",
       " u'citizenship': 2139,\n",
       " u'kadie': 5103,\n",
       " u'fp': 3919,\n",
       " u'challenged': 2018,\n",
       " u'yeah': 9936,\n",
       " u'challenges': 2019,\n",
       " u'year': 9937,\n",
       " u'ft': 3968,\n",
       " u'monitors': 5987,\n",
       " u'fw': 3998,\n",
       " u'improvement': 4679,\n",
       " u'diagnostic': 2998,\n",
       " u'advantages': 861,\n",
       " u'transition': 9101,\n",
       " u'person': 6743,\n",
       " u'altitude': 980,\n",
       " u'tomorrow': 9035,\n",
       " u'fl': 3817,\n",
       " u'caught': 1953,\n",
       " u'cooling': 2533,\n",
       " u'pittsburgh': 6824,\n",
       " u'brains': 1686,\n",
       " u'professionals': 7110,\n",
       " u'transferred': 9098,\n",
       " u'apples': 1094,\n",
       " u'importantly': 4670,\n",
       " u'implications': 4662,\n",
       " u'ralph': 7352,\n",
       " u'chopin': 2095,\n",
       " u'umn': 9274,\n",
       " u'burst': 1790,\n",
       " u'deliver': 2889,\n",
       " u'hurts': 4561,\n",
       " u'passenger': 6660,\n",
       " u'generate': 4056,\n",
       " u'develop': 2980,\n",
       " u'vnet': 9561,\n",
       " u'greetings': 4213,\n",
       " u'death': 2816,\n",
       " u'fortune': 3905,\n",
       " u'roll': 7762,\n",
       " u'output': 6540,\n",
       " u'exposed': 3620,\n",
       " u'francis': 3930,\n",
       " u'scenario': 7936,\n",
       " u'backup': 1369,\n",
       " u'variable': 9455,\n",
       " u'intervention': 4872,\n",
       " u'pitcher': 6819,\n",
       " u'pitched': 6818,\n",
       " u'embedded': 3370,\n",
       " u'604': 522,\n",
       " u'601': 520,\n",
       " u'600': 518,\n",
       " u'602': 521,\n",
       " u'609': 523,\n",
       " u'fools': 3871,\n",
       " u'poor': 6923,\n",
       " u'pool': 6922,\n",
       " u'bulb': 1766,\n",
       " u'religious': 7531,\n",
       " u'keith': 5120,\n",
       " u'chain': 2014,\n",
       " u'volunteer': 9574,\n",
       " u'decide': 2828,\n",
       " u'streets': 8588,\n",
       " u'stalin': 8483,\n",
       " u'ast': 1231,\n",
       " u'pub': 7207,\n",
       " u'excess': 3553,\n",
       " u'darius': 2766,\n",
       " u'inspired': 4802,\n",
       " u'base': 1408,\n",
       " u'advertising': 863,\n",
       " u'jrm': 5056,\n",
       " u'maths': 5726,\n",
       " u'brunswick': 1740,\n",
       " u'producing': 7103,\n",
       " u'petaluma': 6752,\n",
       " u'reject': 7504,\n",
       " u'os2': 6516,\n",
       " u'gizwt': 4114,\n",
       " u'choice': 2090,\n",
       " u'criticize': 2648,\n",
       " u'clarinet': 2162,\n",
       " u'absence': 736,\n",
       " u'evening': 3525,\n",
       " u'ninja': 6235,\n",
       " u'irgun': 4918,\n",
       " u'bless': 1583,\n",
       " u'heavy': 4386,\n",
       " u'praise': 6987,\n",
       " u'american': 996,\n",
       " u'expanded': 3584,\n",
       " u'randomly': 7361,\n",
       " u'hallam': 4289,\n",
       " u'caliber': 1845,\n",
       " u'rockefeller': 7747,\n",
       " u'velocity': 9480,\n",
       " u'physics': 6792,\n",
       " u'phenomenon': 6765,\n",
       " u'competing': 2327,\n",
       " u'respectively': 7622,\n",
       " u'hype': 4570,\n",
       " u'drafted': 3180,\n",
       " u'mcmaster': 5756,\n",
       " u'league': 5321,\n",
       " u'collaborators': 2240,\n",
       " u'minorities': 5901,\n",
       " u'canadians': 1872,\n",
       " u'proton': 7175,\n",
       " u'add': 823,\n",
       " u'orbiter': 6484,\n",
       " u'grant': 4189,\n",
       " u'karl': 5110,\n",
       " u'grand': 4188,\n",
       " u'composition': 2350,\n",
       " u'obviously': 6367,\n",
       " u'flaming': 3822,\n",
       " u'reviewed': 7668,\n",
       " u'questioned': 7294,\n",
       " u'showing': 8187,\n",
       " u'camping': 1867,\n",
       " u'assists': 1218,\n",
       " u'486dx2': 452,\n",
       " u'silence': 8215,\n",
       " u'2tct': 346,\n",
       " u'eaten': 3281,\n",
       " u'subaru': 8626,\n",
       " u'whalers': 9713,\n",
       " u'similar': 8221,\n",
       " u'zionists': 9986,\n",
       " u'ordered': 6489,\n",
       " u'fears': 3725,\n",
       " u'application': 1096,\n",
       " u'department': 2920,\n",
       " u'smiley': 8304,\n",
       " u'compact': 2308,\n",
       " u'cern': 2005,\n",
       " u'v8': 9435,\n",
       " u'telling': 8873,\n",
       " u'lk8': 5476,\n",
       " u'enforce': 3413,\n",
       " u'jump': 5074,\n",
       " u'patents': 6673,\n",
       " u'manage': 5640,\n",
       " u'clara': 2158,\n",
       " u'mirrors': 5912,\n",
       " u'camera': 1862,\n",
       " u'israelis': 4943,\n",
       " u'socket': 8329,\n",
       " u'meet': 5792,\n",
       " u'averages': 1318,\n",
       " u'links': 5439,\n",
       " u'pulling': 7221,\n",
       " u'sought': 8368,\n",
       " u'ronald': 7772,\n",
       " u'encyclopedia': 3404,\n",
       " u'including': 4697,\n",
       " u'bin': 1544,\n",
       " u'university': 9316,\n",
       " u'slide': 8284,\n",
       " u'raised': 7349,\n",
       " u'constitute': 2451,\n",
       " u'special': 8401,\n",
       " u'timer': 8998,\n",
       " u'times': 8999,\n",
       " u'confuse': 2410,\n",
       " u'rck': 7395,\n",
       " u'bastard': 1421,\n",
       " u'grounding': 4227,\n",
       " u'wolves': 9789,\n",
       " u'pulled': 7220,\n",
       " u'wod': 9787,\n",
       " u'tobacco': 9021,\n",
       " u'tyre': 9215,\n",
       " u'ken': 5124,\n",
       " u'kicking': 5151,\n",
       " u'key': 5134,\n",
       " u'limits': 5428,\n",
       " u'hernlem': 4413,\n",
       " u'ami': 1000,\n",
       " u'tuesday': 9178,\n",
       " u'liberals': 5386,\n",
       " u'controlled': 2503,\n",
       " u'controller': 2504,\n",
       " u'surface': 8711,\n",
       " u'examined': 3542,\n",
       " u'speaker': 8396,\n",
       " u'northwest': 6273,\n",
       " u'ut': 9386,\n",
       " u'eklund': 3343,\n",
       " u'46': 443,\n",
       " u'increasingly': 4709,\n",
       " u'liked': 5416,\n",
       " u'distant': 3092,\n",
       " u'41': 428,\n",
       " u'intersection': 4870,\n",
       " u'buphy': 1779,\n",
       " u'roth': 7785,\n",
       " u'amd': 991,\n",
       " u'demonstrates': 2906,\n",
       " u'moderated': 5963,\n",
       " u'inflammation': 4750,\n",
       " u'demonstrated': 2905,\n",
       " u'limitations': 5425,\n",
       " u'1993apr4': 207,\n",
       " u'pointless': 6898,\n",
       " u'additional': 827,\n",
       " u'astro': 1232,\n",
       " u'gain': 4008,\n",
       " u'4t': 467,\n",
       " u'sanders': 7893,\n",
       " u'beats': 1454,\n",
       " u'education': 3312,\n",
       " u'4b': 456,\n",
       " u'4c': 457,\n",
       " u'consists': 2444,\n",
       " u'aug': 1286,\n",
       " u'swap': 8739,\n",
       " u'sorry': 8365,\n",
       " u'void': 9566,\n",
       " u'med': 5784,\n",
       " u'meg': 5796,\n",
       " u'mem': 5805,\n",
       " u'mel': 5801,\n",
       " u'men': 5811,\n",
       " u'zd9': 9977,\n",
       " u'complicated': 2346,\n",
       " u'joshua': 5045,\n",
       " u'objectively': 6348,\n",
       " u'robertson': 7739,\n",
       " u'berlin': 1506,\n",
       " u'room': 7775,\n",
       " u'roof': 7773,\n",
       " u'movies': 6043,\n",
       " u'exceptions': 3551,\n",
       " u'root': 7777,\n",
       " u'manuals': 5662,\n",
       " u'kimbark': 5163,\n",
       " u'personal': 6744,\n",
       " u'crew': 2637,\n",
       " u'schmidt': 7944,\n",
       " u'lmsc': 5481,\n",
       " u'combination': 2267,\n",
       " u'modification': 5967,\n",
       " u'mccall': 5746,\n",
       " u'ya': 9922,\n",
       " u'invented': 4887,\n",
       " u'used': 9370,\n",
       " u'trading': 9084,\n",
       " u'forgot': 3887,\n",
       " u'aids': 911,\n",
       " u'whitespace': 9722,\n",
       " u'cosmic': 2573,\n",
       " u'feds': 3734,\n",
       " u'xsizehints': 9898,\n",
       " u'begins': 1472,\n",
       " u'mario': 5684,\n",
       " u'maria': 5679,\n",
       " u'zealand': 9978,\n",
       " u'organisms': 6498,\n",
       " u'competitors': 2330,\n",
       " u'implying': 4666,\n",
       " u'saturn': 7913,\n",
       " u'troop': 9150,\n",
       " u'testing': 8914,\n",
       " u'vernon': 9491,\n",
       " u'motto': 6029,\n",
       " u'guaranteed': 4241,\n",
       " u'represented': 7581,\n",
       " u'puts': 7242,\n",
       " u'entered': 3435,\n",
       " u'ugly': 9247,\n",
       " u'programs': 7120,\n",
       " u'assigned': 1213,\n",
       " u'fighters': 3765,\n",
       " u'interestingly': 4852,\n",
       " u'dean': 2814,\n",
       " u'deal': 2806,\n",
       " u'deaf': 2805,\n",
       " u'dead': 2802,\n",
       " u'jupiter': 5082,\n",
       " u'dear': 2815,\n",
       " u'microwave': 5864,\n",
       " u'buffer': 1758,\n",
       " u'predicting': 7002,\n",
       " u'greenbelt': 4212,\n",
       " u'operates': 6455,\n",
       " u'afternoon': 881,\n",
       " u'automatically': 1305,\n",
       " u'managers': 5644,\n",
       " u'editor': 3304,\n",
       " u'fraction': 3924,\n",
       " u'batman': 1427,\n",
       " u'shagen': 8128,\n",
       " u'u28037': 9219,\n",
       " u'landing': 5255,\n",
       " u'analyst': 1015,\n",
       " u'utilities': 9393,\n",
       " u'happening': 4317,\n",
       " u'pseudo': 7195,\n",
       " u'restored': 7637,\n",
       " u'premises': 7016,\n",
       " u'father': 3709,\n",
       " u'iraqi': 4916,\n",
       " u'proposals': 7154,\n",
       " u'talked': 8798,\n",
       " u'targets': 8817,\n",
       " u'majors': 5629,\n",
       " u'suspect': 8726,\n",
       " u'processing': 7097,\n",
       " u'box': 1671,\n",
       " u'boy': 1673,\n",
       " u'aspi4dos': 1200,\n",
       " u'bos': 1652,\n",
       " u'diagnosed': 2996,\n",
       " u'bob': 1614,\n",
       " u'hong': 4491,\n",
       " u'uicvm': 9251,\n",
       " u'quoting': 7312,\n",
       " u'fuck': 3971,\n",
       " u'sample': 7886,\n",
       " u'dennis': 2915,\n",
       " u'sunview': 8688,\n",
       " u'sni': 8317,\n",
       " u'membership': 5808,\n",
       " u'police': 6902,\n",
       " u'policy': 6905,\n",
       " u'lunch': 5561,\n",
       " u'applelink': 1093,\n",
       " u'x11': 9862,\n",
       " u'taoism': 8809,\n",
       " u'romans': 7767,\n",
       " u'vision': 9545,\n",
       " u'forsale': 3900,\n",
       " u'waited': 9617,\n",
       " u'speaking': 8398,\n",
       " u'kevin': 5133,\n",
       " u'complexity': 2344,\n",
       " u'interior': 4859,\n",
       " u'201': 244,\n",
       " u'203': 246,\n",
       " u'202': 245,\n",
       " u'205': 249,\n",
       " u'204': 247,\n",
       " u'207': 251,\n",
       " u'206': 250,\n",
       " u'arguing': 1149,\n",
       " u'208': 252,\n",
       " u'harvey': 4340,\n",
       " u'amendment': 994,\n",
       " u'sigma': 8204,\n",
       " u'threshold': 8972,\n",
       " u'treasury': 9116,\n",
       " u'gec': 4049,\n",
       " u'geb': 4048,\n",
       " u'gee': 4050,\n",
       " u'geo': 4073,\n",
       " u'gen': 4052,\n",
       " u'requesting': 7591,\n",
       " u'truetype': 9158,\n",
       " u'miles': 5878,\n",
       " u'london': 5506,\n",
       " u'declared': 2837,\n",
       " u'seas': 7999,\n",
       " u'seat': 8002,\n",
       " u'sean': 7994,\n",
       " u'seal': 7991,\n",
       " u'wonder': 9793,\n",
       " u'boundaries': 1666,\n",
       " u'infrastructure': 4762,\n",
       " u'august': 1287,\n",
       " u'tour': 9064,\n",
       " u'considering': 2440,\n",
       " u'capable': 1886,\n",
       " u'offers': 6394,\n",
       " u'wake': 9619,\n",
       " u'promising': 7135,\n",
       " u'eugene': 3516,\n",
       " u'yr': 9959,\n",
       " u'protein': 7169,\n",
       " u'crary': 2620,\n",
       " u'extended': 3627,\n",
       " u'semitic': 8054,\n",
       " u'flavor': 3826,\n",
       " u'adams': 815,\n",
       " u'jerusalem': 5002,\n",
       " u'plenty': 6874,\n",
       " u'vhs': 9506,\n",
       " u'examine': 3541,\n",
       " u'formed': 3897,\n",
       " u'486': 450,\n",
       " u'480': 448,\n",
       " u'gu': 4239,\n",
       " u'gd': 4045,\n",
       " u'zero': 9981,\n",
       " u'gm': 4129,\n",
       " u'roussel': 7791,\n",
       " u'5000': 472,\n",
       " u'freenet': 3945,\n",
       " u'mentions': 5816,\n",
       " u'africa': 877,\n",
       " u'bruins': 1738,\n",
       " u'engaged': 3417,\n",
       " u'hour': 4520,\n",
       " u'recall': 7432,\n",
       " u'sucks': 8652,\n",
       " u'remain': 7534,\n",
       " u'g6': 4003,\n",
       " u'minimum': 5894,\n",
       " u'homicide': 4482,\n",
       " u'needs': 6174,\n",
       " u'acts': 809,\n",
       " u'maps': 5672,\n",
       " u'sacred': 7864,\n",
       " u'brady': 1684,\n",
       " u'dragon': 3183,\n",
       " u'rand': 7358,\n",
       " u'compound': 2351,\n",
       " u'crohn': 2650,\n",
       " u'viewers': 9520,\n",
       " u'mystery': 6108,\n",
       " u'micro': 5858,\n",
       " u'repeating': 7562,\n",
       " u'portland': 6939,\n",
       " u'singapore': 8237,\n",
       " u'evaluation': 3521,\n",
       " u'backed': 1365,\n",
       " u'maintains': 5625,\n",
       " u'dayton': 2793,\n",
       " u'chart': 2052,\n",
       " u'services': 8098,\n",
       " u'experiment': 3596,\n",
       " u'collins': 2248,\n",
       " u'motorcycles': 6025,\n",
       " u'dante': 2763,\n",
       " u'geoff': 4074,\n",
       " u'mailbox': 5613,\n",
       " u'premise': 7015,\n",
       " u'grounded': 4226,\n",
       " u'foreign': 3881,\n",
       " u'point': 6893,\n",
       " u'tennessee': 8889,\n",
       " u'expensive': 3591,\n",
       " u'glocks': 4124,\n",
       " u'apostle': 1080,\n",
       " u'kurds': 5221,\n",
       " u'evangelical': 3522,\n",
       " u'century': 2002,\n",
       " u'davidian': 2785,\n",
       " u'sun3': 8681,\n",
       " u'1967': 165,\n",
       " u'examining': 3543,\n",
       " u'1963': 163,\n",
       " u'postal': 6954,\n",
       " u'easter': 3277,\n",
       " u'foolish': 3870,\n",
       " u'sizeof': 8256,\n",
       " u'laser': 5273,\n",
       " u'cloud': 2206,\n",
       " u'calstate': 1855,\n",
       " u'tiff': 8991,\n",
       " u'enterpoop': 3437,\n",
       " u'shading': 8124,\n",
       " u'murphy': 6086,\n",
       " u'exterminated': 3632,\n",
       " u'ico': 4587,\n",
       " u'curt': 2705,\n",
       " u'constant': 2448,\n",
       " u'utterly': 9402,\n",
       " u'implied': 4663,\n",
       " u'919': 657,\n",
       " u'presently': 7027,\n",
       " u'faq': 3695,\n",
       " u'entire': 3440,\n",
       " u'radio': 7339,\n",
       " u'related': 7508,\n",
       " u'healing': 4372,\n",
       " u'drops': 3209,\n",
       " u'implement': 4655,\n",
       " u'absolutes': 739,\n",
       " u'holds': 4467,\n",
       " u'varies': 9459,\n",
       " u'profile': 7112,\n",
       " u'located': 5491,\n",
       " u'dixie': 3113,\n",
       " u'sexual': 8115,\n",
       " u'yard': 9931,\n",
       " u'reached': 7398,\n",
       " u'sweden': 8741,\n",
       " u'psilink': 7197,\n",
       " u'bmug': 1606,\n",
       " u'payment': 6686,\n",
       " u'heh': 4390,\n",
       " u'disease': 3075,\n",
       " u'remus': 7551,\n",
       " u'knowledge': 5195,\n",
       " u'teams': 8843,\n",
       " u'maynard': 5739,\n",
       " u'armenia': 1161,\n",
       " u'russ': 7834,\n",
       " u'placebo': 6840,\n",
       " u'comparisons': 2318,\n",
       " u'stores': 8572,\n",
       " u'like': 5415,\n",
       " u'excluding': 3558,\n",
       " u'admitted': 848,\n",
       " u'hair': 4283,\n",
       " u'mode': 5956,\n",
       " u'introduced': 4879,\n",
       " u'rushed': 7832,\n",
       " u'souviens': 8380,\n",
       " u'w11': 9596,\n",
       " u'flip': 3837,\n",
       " u'tricks': 9136,\n",
       " u'rri': 7804,\n",
       " u'drugs': 3212,\n",
       " u'nwu': 6322,\n",
       " u'345': 376,\n",
       " u'348': 377,\n",
       " u'limiting': 5427,\n",
       " u'34u': 379,\n",
       " u'kentucky': 5129,\n",
       " u'dept': 2927,\n",
       " u'selected': 8042,\n",
       " u'revolver': 7674,\n",
       " u'liberty': 5391,\n",
       " u'dineen': 3031,\n",
       " u'beck': 1459,\n",
       " u'leaves': 5332,\n",
       " u'midway': 5869,\n",
       " u'prints': 7069,\n",
       " u'printf': 7067,\n",
       " u'excellent': 3549,\n",
       " u'1280x1024': 75,\n",
       " u'ceremony': 2004,\n",
       " u'description': 2937,\n",
       " u'xtpointer': 9903,\n",
       " u'parallel': 6620,\n",
       " u'suggest': 8663,\n",
       " u'denizens': 2913,\n",
       " u'diseases': 3076,\n",
       " u'detroit': 2978,\n",
       " u'associate': 1219,\n",
       " u'laserwriter': 5275,\n",
       " u'small': 8298,\n",
       " u'days': 2792,\n",
       " u'encouraging': 3399,\n",
       " u'quicker': 7301,\n",
       " u'sarcasm': 7901,\n",
       " u'fiction': 3756,\n",
       " u'frankly': 3934,\n",
       " u'screws': 7974,\n",
       " u'thoroughly': 8960,\n",
       " u'thorough': 8959,\n",
       " u'pkp': 6832,\n",
       " u'situations': 8252,\n",
       " u'minnesota': 5899,\n",
       " u'542': 490,\n",
       " u'545': 491,\n",
       " u'daker': 2746,\n",
       " u'finger': 3790,\n",
       " u'mun': 6078,\n",
       " u'fault': 3712,\n",
       " u'5t': 512,\n",
       " u'expense': 3590,\n",
       " u'code': 2229,\n",
       " u'5m': 508,\n",
       " u'5g': 503,\n",
       " u'censors': 1991,\n",
       " u'rutgers': 7839,\n",
       " u'accessories': 767,\n",
       " u'ocean': 6379,\n",
       " u'judge': 5063,\n",
       " u'expos': 3618,\n",
       " u'breaks': 1701,\n",
       " u'914': 656,\n",
       " u'newshost': 6211,\n",
       " u'54': 489,\n",
       " u'57': 496,\n",
       " u'd012s658': 2734,\n",
       " u'dishonest': 3078,\n",
       " u'election': 3348,\n",
       " u'attacks': 1266,\n",
       " u'duke': 3235,\n",
       " u'ahl': 907,\n",
       " u'ussr': 9382,\n",
       " u'sunlight': 8683,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_   # estraggo il vocabolario   # ho le parole e l'indice di quella parola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00',\n",
       " u'000',\n",
       " u'005',\n",
       " u'01',\n",
       " u'02',\n",
       " u'02238',\n",
       " u'02p',\n",
       " u'03',\n",
       " u'030',\n",
       " u'0358',\n",
       " u'04',\n",
       " u'040',\n",
       " u'0400',\n",
       " u'05',\n",
       " u'06',\n",
       " u'07',\n",
       " u'08',\n",
       " u'09',\n",
       " u'0b',\n",
       " u'0c',\n",
       " u'0d',\n",
       " u'0el',\n",
       " u'0em',\n",
       " u'0g',\n",
       " u'0i',\n",
       " u'0l',\n",
       " u'0m',\n",
       " u'0p',\n",
       " u'0q',\n",
       " u'0qax',\n",
       " u'0t',\n",
       " u'0tbxn',\n",
       " u'0tq',\n",
       " u'0u',\n",
       " u'0w',\n",
       " u'10',\n",
       " u'100',\n",
       " u'1000',\n",
       " u'101',\n",
       " u'102',\n",
       " u'1024',\n",
       " u'1024x768',\n",
       " u'102nd',\n",
       " u'103',\n",
       " u'104',\n",
       " u'105',\n",
       " u'106',\n",
       " u'107',\n",
       " u'108',\n",
       " u'109',\n",
       " u'10k',\n",
       " u'10th',\n",
       " u'11',\n",
       " u'110',\n",
       " u'1100',\n",
       " u'111',\n",
       " u'112',\n",
       " u'113',\n",
       " u'114',\n",
       " u'115',\n",
       " u'116',\n",
       " u'117',\n",
       " u'118',\n",
       " u'119',\n",
       " u'12',\n",
       " u'120',\n",
       " u'1200',\n",
       " u'121',\n",
       " u'122',\n",
       " u'123',\n",
       " u'124',\n",
       " u'125',\n",
       " u'126',\n",
       " u'127',\n",
       " u'128',\n",
       " u'1280x1024',\n",
       " u'129',\n",
       " u'13',\n",
       " u'130',\n",
       " u'131',\n",
       " u'132',\n",
       " u'133',\n",
       " u'134',\n",
       " u'135',\n",
       " u'136',\n",
       " u'137',\n",
       " u'138',\n",
       " u'139',\n",
       " u'13p',\n",
       " u'13q',\n",
       " u'13qs',\n",
       " u'13s',\n",
       " u'14',\n",
       " u'140',\n",
       " u'1400',\n",
       " u'141',\n",
       " u'142',\n",
       " u'143',\n",
       " u'144',\n",
       " u'145',\n",
       " u'146',\n",
       " u'147',\n",
       " u'148',\n",
       " u'149',\n",
       " u'15',\n",
       " u'150',\n",
       " u'1500',\n",
       " u'151',\n",
       " u'152',\n",
       " u'153',\n",
       " u'1542',\n",
       " u'155',\n",
       " u'156',\n",
       " u'157',\n",
       " u'158',\n",
       " u'159',\n",
       " u'15o',\n",
       " u'16',\n",
       " u'160',\n",
       " u'161',\n",
       " u'162',\n",
       " u'163',\n",
       " u'164',\n",
       " u'165',\n",
       " u'16550',\n",
       " u'167',\n",
       " u'168',\n",
       " u'169',\n",
       " u'16m',\n",
       " u'16mb',\n",
       " u'17',\n",
       " u'170',\n",
       " u'172',\n",
       " u'174',\n",
       " u'175',\n",
       " u'176',\n",
       " u'177',\n",
       " u'179',\n",
       " u'18',\n",
       " u'180',\n",
       " u'182',\n",
       " u'184',\n",
       " u'185',\n",
       " u'187',\n",
       " u'188',\n",
       " u'189',\n",
       " u'19',\n",
       " u'190',\n",
       " u'1900',\n",
       " u'1914',\n",
       " u'1915',\n",
       " u'1918',\n",
       " u'1919',\n",
       " u'192',\n",
       " u'1920',\n",
       " u'1923',\n",
       " u'1934',\n",
       " u'1948',\n",
       " u'195',\n",
       " u'1950',\n",
       " u'1958',\n",
       " u'196',\n",
       " u'1960',\n",
       " u'1963',\n",
       " u'1964',\n",
       " u'1967',\n",
       " u'1968',\n",
       " u'1969',\n",
       " u'1970',\n",
       " u'1972',\n",
       " u'1973',\n",
       " u'1974',\n",
       " u'1975',\n",
       " u'1976',\n",
       " u'1977',\n",
       " u'1978',\n",
       " u'1979',\n",
       " u'198',\n",
       " u'1980',\n",
       " u'1981',\n",
       " u'1982',\n",
       " u'1983',\n",
       " u'1984',\n",
       " u'1985',\n",
       " u'1986',\n",
       " u'1987',\n",
       " u'1988',\n",
       " u'1989',\n",
       " u'199',\n",
       " u'1990',\n",
       " u'1991',\n",
       " u'1992',\n",
       " u'1993',\n",
       " u'1993apr12',\n",
       " u'1993apr13',\n",
       " u'1993apr14',\n",
       " u'1993apr15',\n",
       " u'1993apr16',\n",
       " u'1993apr17',\n",
       " u'1993apr18',\n",
       " u'1993apr19',\n",
       " u'1993apr2',\n",
       " u'1993apr20',\n",
       " u'1993apr21',\n",
       " u'1993apr22',\n",
       " u'1993apr23',\n",
       " u'1993apr3',\n",
       " u'1993apr4',\n",
       " u'1993apr5',\n",
       " u'1993apr6',\n",
       " u'1994',\n",
       " u'1995',\n",
       " u'1a',\n",
       " u'1b',\n",
       " u'1c',\n",
       " u'1d',\n",
       " u'1d17',\n",
       " u'1d9',\n",
       " u'1d9l',\n",
       " u'1e',\n",
       " u'1eq',\n",
       " u'1f',\n",
       " u'1f9',\n",
       " u'1fpl',\n",
       " u'1g',\n",
       " u'1j',\n",
       " u'1k',\n",
       " u'1m',\n",
       " u'1mb',\n",
       " u'1p',\n",
       " u'1q',\n",
       " u'1qy',\n",
       " u'1s',\n",
       " u'1st',\n",
       " u'1t',\n",
       " u'1v',\n",
       " u'1w',\n",
       " u'1x',\n",
       " u'1y',\n",
       " u'1z4',\n",
       " u'1z6e',\n",
       " u'20',\n",
       " u'200',\n",
       " u'2000',\n",
       " u'201',\n",
       " u'202',\n",
       " u'203',\n",
       " u'204',\n",
       " u'2048',\n",
       " u'205',\n",
       " u'206',\n",
       " u'207',\n",
       " u'208',\n",
       " u'20mb',\n",
       " u'20th',\n",
       " u'21',\n",
       " u'210',\n",
       " u'211',\n",
       " u'212',\n",
       " u'213',\n",
       " u'214',\n",
       " u'215',\n",
       " u'216',\n",
       " u'217',\n",
       " u'219',\n",
       " u'22',\n",
       " u'220',\n",
       " u'221',\n",
       " u'222',\n",
       " u'223',\n",
       " u'224',\n",
       " u'225',\n",
       " u'226',\n",
       " u'227',\n",
       " u'23',\n",
       " u'230',\n",
       " u'231',\n",
       " u'232',\n",
       " u'234',\n",
       " u'238',\n",
       " u'239',\n",
       " u'24',\n",
       " u'240',\n",
       " u'2400',\n",
       " u'241',\n",
       " u'244',\n",
       " u'245',\n",
       " u'246',\n",
       " u'248',\n",
       " u'249',\n",
       " u'24bit',\n",
       " u'24e',\n",
       " u'24x',\n",
       " u'25',\n",
       " u'250',\n",
       " u'251',\n",
       " u'252',\n",
       " u'253',\n",
       " u'254',\n",
       " u'255',\n",
       " u'256',\n",
       " u'256k',\n",
       " u'257',\n",
       " u'258',\n",
       " u'25mhz',\n",
       " u'26',\n",
       " u'267',\n",
       " u'268',\n",
       " u'27',\n",
       " u'270',\n",
       " u'272',\n",
       " u'273',\n",
       " u'274',\n",
       " u'275',\n",
       " u'278',\n",
       " u'28',\n",
       " u'280',\n",
       " u'282',\n",
       " u'285',\n",
       " u'286',\n",
       " u'287',\n",
       " u'28th',\n",
       " u'29',\n",
       " u'2923',\n",
       " u'294',\n",
       " u'296',\n",
       " u'2_',\n",
       " u'2a',\n",
       " u'2b',\n",
       " u'2d',\n",
       " u'2di',\n",
       " u'2e',\n",
       " u'2f',\n",
       " u'2g',\n",
       " u'2j',\n",
       " u'2k',\n",
       " u'2l',\n",
       " u'2m',\n",
       " u'2mb',\n",
       " u'2nd',\n",
       " u'2p',\n",
       " u'2pl',\n",
       " u'2pu',\n",
       " u'2q',\n",
       " u'2r_',\n",
       " u'2s',\n",
       " u'2tct',\n",
       " u'2tg',\n",
       " u'2tm',\n",
       " u'2u',\n",
       " u'2w',\n",
       " u'2x',\n",
       " u'2y',\n",
       " u'30',\n",
       " u'300',\n",
       " u'3000',\n",
       " u'301',\n",
       " u'303',\n",
       " u'304',\n",
       " u'30602',\n",
       " u'31',\n",
       " u'310',\n",
       " u'312',\n",
       " u'313',\n",
       " u'314',\n",
       " u'316',\n",
       " u'32',\n",
       " u'320',\n",
       " u'323',\n",
       " u'325',\n",
       " u'32bis',\n",
       " u'33',\n",
       " u'330',\n",
       " u'333',\n",
       " u'33mhz',\n",
       " u'34',\n",
       " u'345',\n",
       " u'348',\n",
       " u'34l',\n",
       " u'34u',\n",
       " u'35',\n",
       " u'350',\n",
       " u'353',\n",
       " u'354',\n",
       " u'357',\n",
       " u'358',\n",
       " u'36',\n",
       " u'360',\n",
       " u'364',\n",
       " u'37',\n",
       " u'375',\n",
       " u'38',\n",
       " u'380',\n",
       " u'382761',\n",
       " u'386',\n",
       " u'386bsd',\n",
       " u'386sx',\n",
       " u'39',\n",
       " u'3a',\n",
       " u'3b',\n",
       " u'3c',\n",
       " u'3d',\n",
       " u'3do',\n",
       " u'3dy',\n",
       " u'3e',\n",
       " u'3h',\n",
       " u'3hz',\n",
       " u'3k',\n",
       " u'3l',\n",
       " u'3m',\n",
       " u'3n',\n",
       " u'3o',\n",
       " u'3p',\n",
       " u'3q',\n",
       " u'3rd',\n",
       " u'3t',\n",
       " u'3tc',\n",
       " u'3v9',\n",
       " u'3v9f0',\n",
       " u'3w2tm',\n",
       " u'3x',\n",
       " u'40',\n",
       " u'400',\n",
       " u'4000',\n",
       " u'403',\n",
       " u'405',\n",
       " u'407',\n",
       " u'408',\n",
       " u'41',\n",
       " u'410',\n",
       " u'412',\n",
       " u'415',\n",
       " u'416',\n",
       " u'42',\n",
       " u'427',\n",
       " u'43',\n",
       " u'44',\n",
       " u'444',\n",
       " u'45',\n",
       " u'450',\n",
       " u'455',\n",
       " u'456',\n",
       " u'458',\n",
       " u'46',\n",
       " u'460',\n",
       " u'462',\n",
       " u'47',\n",
       " u'48',\n",
       " u'480',\n",
       " u'4800',\n",
       " u'486',\n",
       " u'486dx',\n",
       " u'486dx2',\n",
       " u'49',\n",
       " u'492',\n",
       " u'494',\n",
       " u'4b',\n",
       " u'4c',\n",
       " u'4d',\n",
       " u'4e',\n",
       " u'4f',\n",
       " u'4k',\n",
       " u'4l',\n",
       " u'4m',\n",
       " u'4mb',\n",
       " u'4p',\n",
       " u'4r',\n",
       " u'4t',\n",
       " u'4th',\n",
       " u'4u',\n",
       " u'50',\n",
       " u'500',\n",
       " u'5000',\n",
       " u'503',\n",
       " u'508',\n",
       " u'509',\n",
       " u'50mhz',\n",
       " u'51',\n",
       " u'510',\n",
       " u'512',\n",
       " u'512k',\n",
       " u'513',\n",
       " u'515',\n",
       " u'516',\n",
       " u'518',\n",
       " u'52',\n",
       " u'520',\n",
       " u'525',\n",
       " u'53',\n",
       " u'54',\n",
       " u'542',\n",
       " u'545',\n",
       " u'54715',\n",
       " u'55',\n",
       " u'550',\n",
       " u'56',\n",
       " u'57',\n",
       " u'571',\n",
       " u'575',\n",
       " u'58',\n",
       " u'580',\n",
       " u'581',\n",
       " u'59',\n",
       " u'5g',\n",
       " u'5g9p',\n",
       " u'5g9v',\n",
       " u'5j',\n",
       " u'5k',\n",
       " u'5m',\n",
       " u'5mb',\n",
       " u'5p',\n",
       " u'5s',\n",
       " u'5t',\n",
       " u'5th',\n",
       " u'5u',\n",
       " u'5v',\n",
       " u'5w',\n",
       " u'60',\n",
       " u'600',\n",
       " u'6000',\n",
       " u'601',\n",
       " u'602',\n",
       " u'604',\n",
       " u'609',\n",
       " u'61',\n",
       " u'610',\n",
       " u'612',\n",
       " u'613',\n",
       " u'614',\n",
       " u'617',\n",
       " u'619',\n",
       " u'62',\n",
       " u'621',\n",
       " u'624',\n",
       " u'629',\n",
       " u'63',\n",
       " u'64',\n",
       " u'640x480',\n",
       " u'647',\n",
       " u'64k',\n",
       " u'65',\n",
       " u'650',\n",
       " u'66',\n",
       " u'663',\n",
       " u'666',\n",
       " u'67',\n",
       " u'675',\n",
       " u'68',\n",
       " u'68000',\n",
       " u'68030',\n",
       " u'68040',\n",
       " u'685',\n",
       " u'69',\n",
       " u'6_',\n",
       " u'6a',\n",
       " u'6c',\n",
       " u'6e',\n",
       " u'6e1t',\n",
       " u'6ei',\n",
       " u'6ei4',\n",
       " u'6ej',\n",
       " u'6f',\n",
       " u'6f1',\n",
       " u'6g',\n",
       " u'6k',\n",
       " u'6l',\n",
       " u'6n',\n",
       " u'6p',\n",
       " u'6ql',\n",
       " u'6t',\n",
       " u'6th',\n",
       " u'6u',\n",
       " u'6um',\n",
       " u'6umu',\n",
       " u'6v',\n",
       " u'6w',\n",
       " u'6x',\n",
       " u'70',\n",
       " u'700',\n",
       " u'7000',\n",
       " u'703',\n",
       " u'706',\n",
       " u'708',\n",
       " u'70s',\n",
       " u'71',\n",
       " u'713',\n",
       " u'714',\n",
       " u'72',\n",
       " u'73',\n",
       " u'730',\n",
       " u'734',\n",
       " u'74',\n",
       " u'7415',\n",
       " u'75',\n",
       " u'750',\n",
       " u'75di',\n",
       " u'75u',\n",
       " u'76',\n",
       " u'768',\n",
       " u'77',\n",
       " u'78',\n",
       " u'79',\n",
       " u'7b',\n",
       " u'7ex',\n",
       " u'7ey',\n",
       " u'7ez',\n",
       " u'7g',\n",
       " u'7klj',\n",
       " u'7kn',\n",
       " u'7r',\n",
       " u'7t',\n",
       " u'7th',\n",
       " u'7tl',\n",
       " u'7tu',\n",
       " u'7u',\n",
       " u'7v',\n",
       " u'7z',\n",
       " u'80',\n",
       " u'800',\n",
       " u'8000',\n",
       " u'800x600',\n",
       " u'801',\n",
       " u'804',\n",
       " u'805',\n",
       " u'8051',\n",
       " u'80ns',\n",
       " u'81',\n",
       " u'818',\n",
       " u'82',\n",
       " u'83',\n",
       " u'838',\n",
       " u'84',\n",
       " u'85',\n",
       " u'850',\n",
       " u'8514',\n",
       " u'86',\n",
       " u'87',\n",
       " u'88',\n",
       " u'89',\n",
       " u'891',\n",
       " u'8bit',\n",
       " u'8c',\n",
       " u'8c_',\n",
       " u'8k',\n",
       " u'8mb',\n",
       " u'8n',\n",
       " u'8p',\n",
       " u'8th',\n",
       " u'8v',\n",
       " u'8y',\n",
       " u'90',\n",
       " u'900',\n",
       " u'9000',\n",
       " u'908',\n",
       " u'91',\n",
       " u'91109',\n",
       " u'914',\n",
       " u'919',\n",
       " u'92',\n",
       " u'922',\n",
       " u'93',\n",
       " u'93105',\n",
       " u'94',\n",
       " u'94305',\n",
       " u'95',\n",
       " u'950',\n",
       " u'96',\n",
       " u'9600',\n",
       " u'97',\n",
       " u'975',\n",
       " u'9760',\n",
       " u'98',\n",
       " u'99',\n",
       " u'9937',\n",
       " u'9c',\n",
       " u'9d',\n",
       " u'9f',\n",
       " u'9f8',\n",
       " u'9f9',\n",
       " u'9f9f',\n",
       " u'9h',\n",
       " u'9l',\n",
       " u'9l3',\n",
       " u'9m',\n",
       " u'9p',\n",
       " u'9s',\n",
       " u'9v',\n",
       " u'9z',\n",
       " u'__',\n",
       " u'___',\n",
       " u'____',\n",
       " u'_____',\n",
       " u'______',\n",
       " u'_______',\n",
       " u'________',\n",
       " u'_________',\n",
       " u'__________',\n",
       " u'_______________________________________________________________________________',\n",
       " u'________________________________________________________________________________',\n",
       " u'_d',\n",
       " u'_is_',\n",
       " u'_l',\n",
       " u'_lw',\n",
       " u'_n',\n",
       " u'_not_',\n",
       " u'_o',\n",
       " u'_q',\n",
       " u'_the',\n",
       " u'a1',\n",
       " u'a2',\n",
       " u'a3',\n",
       " u'a4',\n",
       " u'a7',\n",
       " u'a85',\n",
       " u'a86',\n",
       " u'a865',\n",
       " u'a86r',\n",
       " u'a945',\n",
       " u'aa',\n",
       " u'aaa',\n",
       " u'aaron',\n",
       " u'aau',\n",
       " u'ab',\n",
       " u'abandoned',\n",
       " u'abc',\n",
       " u'abiding',\n",
       " u'abilities',\n",
       " u'ability',\n",
       " u'able',\n",
       " u'abo',\n",
       " u'abolish',\n",
       " u'abort',\n",
       " u'abortion',\n",
       " u'abraham',\n",
       " u'abroad',\n",
       " u'abs',\n",
       " u'absence',\n",
       " u'absolute',\n",
       " u'absolutely',\n",
       " u'absolutes',\n",
       " u'abstinence',\n",
       " u'abstract',\n",
       " u'abstracts',\n",
       " u'absurd',\n",
       " u'abu',\n",
       " u'abuse',\n",
       " u'abused',\n",
       " u'abuses',\n",
       " u'ac',\n",
       " u'acad',\n",
       " u'acad3',\n",
       " u'academic',\n",
       " u'academy',\n",
       " u'acc',\n",
       " u'accelerate',\n",
       " u'accelerated',\n",
       " u'acceleration',\n",
       " u'accelerator',\n",
       " u'accelerators',\n",
       " u'accept',\n",
       " u'acceptable',\n",
       " u'acceptance',\n",
       " u'accepted',\n",
       " u'accepting',\n",
       " u'accepts',\n",
       " u'access',\n",
       " u'accessible',\n",
       " u'accessories',\n",
       " u'accident',\n",
       " u'accidental',\n",
       " u'accidentally',\n",
       " u'accidents',\n",
       " u'accomplish',\n",
       " u'accomplished',\n",
       " u'accord',\n",
       " u'according',\n",
       " u'account',\n",
       " u'accounting',\n",
       " u'accounts',\n",
       " u'accuracy',\n",
       " u'accurate',\n",
       " u'accurately',\n",
       " u'accuse',\n",
       " u'accused',\n",
       " u'ace',\n",
       " u'achieve',\n",
       " u'achieved',\n",
       " u'acid',\n",
       " u'acker',\n",
       " u'acknowledge',\n",
       " u'acknowledged',\n",
       " u'aclu',\n",
       " u'acm',\n",
       " u'acns',\n",
       " u'acpub',\n",
       " u'acquire',\n",
       " u'acquired',\n",
       " u'acquisition',\n",
       " u'acs',\n",
       " u'acsu',\n",
       " u'act',\n",
       " u'acting',\n",
       " u'action',\n",
       " u'actions',\n",
       " u'active',\n",
       " u'actively',\n",
       " u'activists',\n",
       " u'activities',\n",
       " u'activity',\n",
       " u'acts',\n",
       " u'actual',\n",
       " u'actually',\n",
       " u'acute',\n",
       " u'ad',\n",
       " u'adam',\n",
       " u'adams',\n",
       " u'adaptec',\n",
       " u'adapted',\n",
       " u'adapter',\n",
       " u'adapters',\n",
       " u'adaptor',\n",
       " u'adb',\n",
       " u'adcom',\n",
       " u'add',\n",
       " u'added',\n",
       " u'adding',\n",
       " u'addition',\n",
       " u'additional',\n",
       " u'additionally',\n",
       " u'additions',\n",
       " u'address',\n",
       " u'addressed',\n",
       " u'addresses',\n",
       " u'addressing',\n",
       " u'adds',\n",
       " u'adelaide',\n",
       " u'adequate',\n",
       " u'adequately',\n",
       " u'adirondack',\n",
       " u'adjust',\n",
       " u'adjusted',\n",
       " u'adjustment',\n",
       " u'adl',\n",
       " u'admin',\n",
       " u'administration',\n",
       " u'administrative',\n",
       " u'administrator',\n",
       " u'admit',\n",
       " u'admitted',\n",
       " u'admittedly',\n",
       " u'adobe',\n",
       " u'adopt',\n",
       " u'adopted',\n",
       " u'adrian',\n",
       " u'ads',\n",
       " u'adult',\n",
       " u'adults',\n",
       " u'advance',\n",
       " u'advanced',\n",
       " u'advances',\n",
       " u'advantage',\n",
       " u'advantages',\n",
       " u'advertised',\n",
       " u'advertising',\n",
       " u'advice',\n",
       " u'advisory',\n",
       " u'advocate',\n",
       " u'advocates',\n",
       " u'ae',\n",
       " u'aerospace',\n",
       " u'af',\n",
       " u'affair',\n",
       " u'affairs',\n",
       " u'affect',\n",
       " u'affected',\n",
       " u'afford',\n",
       " u'afraid',\n",
       " u'africa',\n",
       " u'african',\n",
       " u'afterlife',\n",
       " u'aftermarket',\n",
       " u'afternoon',\n",
       " u'ag',\n",
       " u'agate',\n",
       " u'agdam',\n",
       " u'age',\n",
       " u'aged',\n",
       " u'agencies',\n",
       " u'agency',\n",
       " u'agenda',\n",
       " u'agent',\n",
       " u'agents',\n",
       " u'ages',\n",
       " u'aggression',\n",
       " u'aggressive',\n",
       " u'agnostic',\n",
       " u'agnostics',\n",
       " u'ago',\n",
       " u'agree',\n",
       " u'agreed',\n",
       " u'agreement',\n",
       " u'agreements',\n",
       " u'agrees',\n",
       " u'agricultural',\n",
       " u'ah',\n",
       " u'ahead',\n",
       " u'ahf',\n",
       " u'ahl',\n",
       " u'ahmet',\n",
       " u'ai',\n",
       " u'aid',\n",
       " u'aids',\n",
       " u'aiken',\n",
       " u'aim',\n",
       " u'aimed',\n",
       " u'ain',\n",
       " u'air',\n",
       " u'aircraft',\n",
       " u'airplane',\n",
       " u'airport',\n",
       " u'aisun3',\n",
       " u'aix',\n",
       " u'aj',\n",
       " u'ajr',\n",
       " u'ajz',\n",
       " u'ak',\n",
       " u'ak296',\n",
       " u'aka',\n",
       " u'al',\n",
       " u'ala',\n",
       " u'alabama',\n",
       " u'alan',\n",
       " u'alarm',\n",
       " u'alas',\n",
       " u'alaska',\n",
       " u'albany',\n",
       " u'albert',\n",
       " u'alberta',\n",
       " u'albicans',\n",
       " u'alchemy',\n",
       " u'alcohol',\n",
       " u'alert',\n",
       " u'alex',\n",
       " u'alexander',\n",
       " u'alexia',\n",
       " u'algorithm',\n",
       " u'algorithms',\n",
       " u'ali',\n",
       " u'alias',\n",
       " u'alice',\n",
       " u'alicea',\n",
       " u'alien',\n",
       " u'alignment',\n",
       " u'alike',\n",
       " u'alink',\n",
       " u'alive',\n",
       " u'allah',\n",
       " u'allan',\n",
       " u'alleged',\n",
       " u'allegedly',\n",
       " u'allen',\n",
       " u'allergic',\n",
       " u'allergy',\n",
       " u'allies',\n",
       " u'allocated',\n",
       " u'allocation',\n",
       " u'allow',\n",
       " u'allowed',\n",
       " u'allowing',\n",
       " u'allows',\n",
       " u'almanac',\n",
       " u'alomar',\n",
       " u'alot',\n",
       " u'alpha',\n",
       " u'alt',\n",
       " u'alter',\n",
       " u'altered',\n",
       " u'alternate',\n",
       " u'alternative',\n",
       " u'alternatives',\n",
       " u'altitude',\n",
       " u'altogether',\n",
       " u'aludra',\n",
       " u'aluminum',\n",
       " u'ama',\n",
       " u'amanda',\n",
       " u'amateur',\n",
       " u'amazed',\n",
       " u'amazing',\n",
       " u'ambassador',\n",
       " u'ambulance',\n",
       " u'amd',\n",
       " u'amdahl',\n",
       " u'amend',\n",
       " u'amendment',\n",
       " u'america',\n",
       " u'american',\n",
       " u'americans',\n",
       " u'ames',\n",
       " u'amherst',\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()  # ho le parole ordinate per ordine alfabetico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'car', u'nntp', u'posting', u'host', u'wam', u'umd', u'edu',\n",
       "       u'university', u'maryland', u'college', u'park', u'15',\n",
       "       u'wondering', u'enlighten', u'saw', u'day', u'door', u'sports',\n",
       "       u'looked', u'late', u'early', u'70s', u'called', u'doors',\n",
       "       u'really', u'small', u'addition', u'bumper', u'separate', u'rest',\n",
       "       u'body', u'know', u'model', u'engine', u'specs', u'years',\n",
       "       u'production', u'history', u'info', u'looking', u'mail', u'thanks',\n",
       "       u'il', u'brought', u'neighborhood'], \n",
       "      dtype='<U80')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(vectorizer.get_feature_names())[counts[0].nonzero()[1]] \n",
    "#trasformo il vectorizer che è un dizionario in array e conto i non zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1898, 6250, 6958, 4513, 9631, 9272, 3310, 9316, 5703, 2247, 6631,\n",
       "        104, 9796, 3431, 7921, 2791, 3156, 8443, 5512, 5276, 3267,  583,\n",
       "       1849, 3157, 7419, 8298,  826, 1776, 8074, 7633, 1619, 5193, 5957,\n",
       "       3419, 8413, 9938, 7105, 4444, 4755, 5513, 5612, 8925, 4630, 1734,\n",
       "       6183], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[0].nonzero()[1]  # sono le parole che non sono zero\n",
    "# counts è una matice sparsa, ne prendo il primo doc, prendo gli indici degli elementi che non son zero,\n",
    "# ne prendo la seconda parte che sono solo le colonne [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[0].data  # car 5 volte, e le altre hanno freq 1. Counts è una matrice sparsa, mi dà le freq solo dei non zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = text.CountVectorizer(max_df=0.8,\n",
    "                                  max_features=10000, \n",
    "                                  stop_words=text.ENGLISH_STOP_WORDS,\n",
    "                                 ngram_range=(1,2))\n",
    "\n",
    "                                # ngram_range mi dà le coppie di parole \n",
    "    # LA DIFFERENZA RISPETTO AL CODICE PRECEDENTE E' CHE QUI HO LE COPPIE DI PAROLE\n",
    "    \n",
    "counts = vectorizer.fit_transform(documents)  \n",
    "tfidf = text.TfidfTransformer().fit_transform(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'car', u'nntp', u'posting', u'host', u'wam', u'umd', u'edu',\n",
       "       u'university', u'maryland', u'college', u'park', u'15',\n",
       "       u'wondering', u'saw', u'day', u'door', u'sports', u'looked',\n",
       "       u'late', u'early', u'called', u'doors', u'really', u'small',\n",
       "       u'addition', u'bumper', u'separate', u'rest', u'body', u'know',\n",
       "       u'model', u'engine', u'specs', u'years', u'production', u'history',\n",
       "       u'info', u'looking', u'mail', u'thanks', u'il', u'brought',\n",
       "       u'neighborhood', u'nntp posting', u'posting host', u'wam umd',\n",
       "       u'umd edu', u'edu organization', u'organization university',\n",
       "       u'university maryland', u'maryland college', u'college park',\n",
       "       u'lines 15', u'mail thanks'], \n",
       "      dtype='<U80')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(vectorizer.get_feature_names())[counts[0].nonzero()[1]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing with NLTK\n",
    "\n",
    "NLTK (Natural Language ToolKit) is a library for symbolic and statistical natural language processing (NLP).\n",
    "\n",
    "It supports a few functionalities for NLP, such as:\n",
    "\n",
    "- Lexical analysis: Word and text tokenizer\n",
    "- n-gram and collocations\n",
    "- Part-of-speech tagger\n",
    "- Tree model and Text chunker for capturing\n",
    "- Named-entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stemming = rimuove la parte finale della parola\n",
    "# lemma ritorna un'altra parola trasformata\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import stem\n",
    "import re\n",
    "\n",
    "pattern = re.compile('(?u)\\\\b[A-Za-z]{3,}')\n",
    "\n",
    "stemmer = stem.SnowballStemmer('english')\n",
    "def stemming(doc):\n",
    "    l = [stemmer.stem(t) for t in pattern.findall(doc)]\n",
    "    return [w for w in l if len(w) > 2]\n",
    "\n",
    "wnl = stem.WordNetLemmatizer()\n",
    "def lemmatize(doc):\n",
    "    \n",
    "    def lemma(w):\n",
    "        l = wnl.lemmatize(t, wn.NOUN)\n",
    "        if l == w:\n",
    "            l = wnl.lemmatize(t, wn.ADJ)\n",
    "        if l == w:\n",
    "            l = wnl.lemmatize(t, wn.ADV)\n",
    "        if l == w:\n",
    "            l = wnl.lemmatize(t, wn.VERB)\n",
    "        return l\n",
    "    \n",
    "    l = [lemma(t) for t in pattern.findall(doc)]\n",
    "    return [w for w in l if len(w) > 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/bigdive/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For grammatical reasons, documents are going to use different forms of a word,\n",
      "such as organize, organizes, and organizing.\n",
      "Additionally, there are families of derivationally related words with similar meanings,\n",
      "such as democracy, democratic, and democratization.\n",
      "\n",
      "[u'for', u'grammat', u'reason', u'document', u'are', u'use', u'differ', u'form', u'word', u'such', u'organ', u'organ', u'and', u'organ', u'addit', u'there', u'are', u'famili', u'deriv', u'relat', u'word', u'with', u'similar', u'mean', u'such', u'democraci', u'democrat', u'and', u'democrat']\n",
      "\n",
      "['For', 'grammatical', u'reason', u'document', 'use', 'different', u'form', 'word', 'such', 'organize', u'organize', 'and', u'organize', 'Additionally', 'there', u'family', 'derivationally', u'relate', u'word', 'with', 'similar', u'meaning', 'such', 'democracy', 'democratic', 'and', 'democratization']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"For grammatical reasons, documents are going to use different forms of a word,\n",
    "such as organize, organizes, and organizing.\n",
    "Additionally, there are families of derivationally related words with similar meanings,\n",
    "such as democracy, democratic, and democratization.\"\"\"\n",
    "\n",
    "print sentence\n",
    "print\n",
    "print stemming(sentence)\n",
    "print\n",
    "print lemmatize(sentence)\n",
    "\n",
    "# l'output è diviso in due parti: (organize.....ecc....)\n",
    "# stemming: rimuove la parte finale della parola, fa lo stemming della parola sulla root (radice della parola)\n",
    "# lemmatize: trasforma la parola in una parola nomalizzata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = text.CountVectorizer(max_df=0.95, \n",
    "                                  min_df=3,\n",
    "                                  max_features=10000, \n",
    "                                  stop_words='english',\n",
    "                                  encoding='latin1', \n",
    "                                  tokenizer=lemmatize,  # tokenizer = prende il testo e ritorna una lista di parole\n",
    "                                  ngram_range=(1, 2))\n",
    "counts = vectorizer.fit_transform(dataset.data)\n",
    "tfidf = text.TfidfTransformer().fit_transform(counts)\n",
    "\n",
    "# per ogni testo, fa il processo di lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'car', u'nntp', u'post', u'host', u'wam', u'umd', u'edu',\n",
       "       u'university', u'maryland', u'college', u'park', u'wonder',\n",
       "       u'enlighten', u'saw', u'day', u'door', u'sport', u'look', u'late',\n",
       "       u'early', u'really', u'small', u'addition', u'bumper', u'separate',\n",
       "       u'rest', u'body', u'know', u'model', u'engine', u'spec', u'year',\n",
       "       u'production', u'make', u'history', u'info', u'mail', u'thank',\n",
       "       u'bring', u'neighborhood', u'subject car', u'nntp post',\n",
       "       u'post host', u'wam umd', u'umd edu', u'edu organization',\n",
       "       u'organization university', u'university maryland',\n",
       "       u'maryland college', u'college park', u'park line', u'line wonder',\n",
       "       u'sport car', u'mail thank'], \n",
       "      dtype='<U26')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(vectorizer.get_feature_names())[counts[0].nonzero()[1]] \n",
    "# adesso ho tutte le parole normalizzate (es. sports è diventato sport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a variable, tfidf, which is a vectorizer responsible for performing three important steps:\n",
    "\n",
    "- First, it will build a dictionary of features where keys are terms and values are indices of the term in the feature matrix (that's the fit part in fit_transform)\n",
    "- Second, it will transform our documents into numerical feature vectors according to the frequency of words appearing in each text message. Since any one text message is short, each feature vector will be made up of mostly zeros, each of which indicates that a given word appeared zero times in that message.\n",
    "- Lastly, it will compute the tf-idf weights for our term frequency matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonnegative Matrix Factorization for Topic extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine having 5 documents, 2 of them about environment and 2 of them about U.S. Congress and 1 about both, that means it says about government legislation process in protecting an environment. We need to write a program that unmistakably identifies category of each document and also returns a degree of belonging of each document to a particular category. For this elementary example we limit our vocabulary to 5 words: AIR, WATER, POLLUTION, DEMOCRAT, REPUBLICAN. Category ENVIRONMENT and category CONGRESS may contain all 5 words but with different probability. We understand that the word POLLUTION has more chances to be in the article about ENVIRONMENT than in the article about CONGRESS, but can theoretically be in both. Presume after an examination of our data we built following document-term table:\n",
    "\n",
    "<table border=\"\" cellpadding=\"3\" style=\"font-family:'Times New Roman'\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>document/word</td>\n",
    "<td>air</td>\n",
    "<td>water</td>\n",
    "<td>pollution</td>\n",
    "<td>democrat</td>\n",
    "<td>republican</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 1</td>\n",
    "<td>3</td>\n",
    "<td>2</td>\n",
    "<td>8</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 2</td>\n",
    "<td>1</td>\n",
    "<td>4</td>\n",
    "<td>12</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 3</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>10</td>\n",
    "<td>11</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 4</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>8</td>\n",
    "<td>5</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 5</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "<td>1</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "We distinguish our categories by the group of words assigned to them. We decide that category ENVIRONMENT normally should contain only words AIR, WATER, POLLUTION and category CONGRESS should contain only words DEMOCRAT and REPUBLICAN. We build another matrix, each row of which represent category and contains counts for only words that assigned to each category. \n",
    "\n",
    "<table border=\"\" cellpadding=\"3\" style=\"font-family:'Times New Roman'\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>categories</td>\n",
    "<td>air</td>\n",
    "<td>water</td>\n",
    "<td>pollution</td>\n",
    "<td>democrat</td>\n",
    "<td>republican</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>ENVIRONMENT</td>\n",
    "<td>5</td>\n",
    "<td>7</td>\n",
    "<td>21</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>CONGRESS</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>19</td>\n",
    "<td>17</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "We change values from frequencies to probabilities by dividing them by sums in rows, which turns each row into probability distribution.\n",
    "\n",
    "<table border=\"\" cellpadding=\"3\" style=\"font-family:'Times New Roman'\">\n",
    "<caption>Matrix&nbsp;<strong>H</strong></caption>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>categories</td>\n",
    "<td>air</td>\n",
    "<td>water</td>\n",
    "<td>pollution</td>\n",
    "<td>democrat</td>\n",
    "<td>republican</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>ENVIRONMENT</td>\n",
    "<td>0.15</td>\n",
    "<td>0.21</td>\n",
    "<td>0.64</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>CONGRESS</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0</td>\n",
    "<td>0.53</td>\n",
    "<td>0.47</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Now we create another matrix that contains probability distribution for categories within each document that looks like follows:\n",
    "\n",
    "<table border=\"\" cellpadding=\"3\" style=\"font-family:'Times New Roman'\">\n",
    "<caption>Matrix&nbsp;<strong>W</strong></caption>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>documents</td>\n",
    "<td>ENVIRONMENT</td>\n",
    "<td>CONGRESS</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 1</td>\n",
    "<td>1.0</td>\n",
    "<td>0.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 2</td>\n",
    "<td>1.0</td>\n",
    "<td>0.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 3</td>\n",
    "<td>0.0</td>\n",
    "<td>1.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 4</td>\n",
    "<td>0.0</td>\n",
    "<td>1.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>doc 5</td>\n",
    "<td>0.6</td>\n",
    "<td>0.4</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "It shows that top two documents speak about environment, next two about congress and last document about both. Ratios 0.6 and 0.4 for the last document are defined by 3 words from environment category and 2 words from congress category. Now we multiply both matrices and compare the result with original data but in a normalized form. Normalization in this case is division of each row by the sum of all elements in rows. The comparison is shown side-by-side below:\n",
    "\n",
    "<table cellpadding=\"10\" style=\"font-family:'Times New Roman'\">\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>\n",
    "<table border=\"\" cellpadding=\"3\">\n",
    "<caption>Product of&nbsp;<strong>W * H</strong></caption>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>0.15</td>\n",
    "<td>0.21</td>\n",
    "<td>0.64</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.15</td>\n",
    "<td>0.21</td>\n",
    "<td>0.64</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.53</td>\n",
    "<td>0.47</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.53</td>\n",
    "<td>0.47</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.09</td>\n",
    "<td>0.13</td>\n",
    "<td>0.38</td>\n",
    "<td>0.21</td>\n",
    "<td>0.19</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</td>\n",
    "<td>\n",
    "<table border=\"\" cellpadding=\"3\">\n",
    "<caption>Normalized data&nbsp;<strong>N</strong></caption>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>0.23</td>\n",
    "<td>0.15</td>\n",
    "<td>0.62</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.06</td>\n",
    "<td>0.24</td>\n",
    "<td>0.70</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.48</td>\n",
    "<td>0.52</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.0</td>\n",
    "<td>0.61</td>\n",
    "<td>0.39</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>0.2</td>\n",
    "<td>0.2</td>\n",
    "<td>0.2</td>\n",
    "<td>0.2</td>\n",
    "<td>0.2</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "The correlation is obvious. The problem definition is to find constrained matrices W and H (given the number of categories), product of which is the best match with normalized data N. When approximation is found matrix H will contain sought categories.\n",
    "\n",
    "**Formally**, we are trying to minimize this:\n",
    "\n",
    "$$ \\|\\mathbf{N} - \\mathbf{WH}\\|^2_F $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# il prodotto delle matrici W * H deve essere il più simile possibile alla matrice N (decomposizione di N in W e H)\n",
    "# quindi minimizzo questa differenza\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "# Fit the NMF model\n",
    "nmf = decomposition.NMF(n_components=6)   # NMF = Non Negative Matrix Factorization\n",
    "nmf.fit(tfidf)\n",
    "W = nmf.transform(tfidf)   # matrice W = peso\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape   # per ognuno degli 11.314 elementi ho un peso per i 6 elementi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.00088278,  0.        , ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 5384, 5383, ..., 1512, 1406, 4691])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H[0].argsort()  # mi dà gli indici ordinati per peso\n",
    "# l'ultima parola ha il peso maggiore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4867, 2888, 7761, 5823, 4694, 5969, 7753, 6933, 7762, 2024,  209,\n",
       "       6530, 1594, 9301, 1513, 3666, 2982, 2889, 1512, 1406])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H[0].argsort()[-21:-1]\n",
    "# prendo gli ultimi 20 termini in ordine inverso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inverse the vectorizer vocabulary to be able\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'law', u'encrypt', u'secure', u'netcom', u'key escrow', u'nsa', u'secret', u'public', u'security', u'crypto', u'algorithm', u'phone', u'com', u'use', u'clipper chip', u'government', u'escrow', u'encryption', u'clipper', u'chip']\n"
     ]
    }
   ],
   "source": [
    "print[feature_names[i] for i in H[0].argsort()[-21:-1]]\n",
    "# qui al posto degli indici ho le corrispondenti parole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "key,chip,clipper,encryption,escrow,government,clipper chip,use,com,phone,algorithm,crypto,security,public,secret,nsa,key escrow,netcom,secure,encrypt\n",
      "\n",
      "Topic #1:\n",
      "god,people,say,christian,jesus,think,believe,don,make,know,write,life,bible,right,just,thing,time,law,religion,come\n",
      "\n",
      "Topic #2:\n",
      "pitt,pitt edu,gordon bank,geb,gordon,bank,geb pitt,edu gordon,cadre,bank skepticism,chastity intellect,skepticism chastity,shameful surrender,geb cadre,edu shameful,cadre dsl,intellect geb,dsl pitt,surrender soon,dsl\n",
      "\n",
      "Topic #3:\n",
      "window,file,use,card,drive,problem,program,driver,run,disk,thank,scsi,work,help,graphic,color,video,version,mac,need\n",
      "\n",
      "Topic #4:\n",
      "game,team,player,play,win,year,hockey,season,score,good,baseball,nhl,fan,league,playoff,think,toronto,run,pitch,hit\n",
      "\n",
      "Topic #5:\n",
      "edu,post,nntp,nntp post,host,post host,com,article,university,write,line nntp,car,distribution,usa,organization university,reply,bike,state,line distribution,cwru\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, topic in enumerate(H):\n",
    "    print \"Topic #%d:\" % topic_idx\n",
    "    print \",\".join([feature_names[i] for i in topic.argsort()[:-21:-1]])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Compare the results of Nonnegative Matrix Factorization (NMF) with Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=6, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "# Fit the LDA model\n",
    "lda = decomposition.LatentDirichletAllocation(n_topics=6)  \n",
    "lda.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = lda.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "ohio,ohio state,nasa,cwru,cwru edu,cleveland,state edu,pitt,magnus,nasa gov,gordon bank,case western,gordon,geb,western reserve,reserve university,organization case,henry,magnus ohio,alaska\n",
      "\n",
      "Topic #1:\n",
      "key,clipper,encryption,chip,digex,access digex,access,stratus,escrow,clipper chip,nsa,crypto,stratus com,pgp,wpi,mellon,digex net,security,carnegie,carnegie mellon\n",
      "\n",
      "Topic #2:\n",
      "window,use,edu,thank,file,card,drive,university,post,com,host,nntp,nntp post,post host,problem,program,mail,need,work,help\n",
      "\n",
      "Topic #3:\n",
      "edu,com,write,article,say,people,think,don,post,good,just,make,like,know,god,year,university,time,host,nntp\n",
      "\n",
      "Topic #4:\n",
      "israel,israeli,arab,columbia,columbia edu,jew,palestinian,uci,mcgill,uci edu,gld,lebanese,ingr,cunixb,cunixb columbia,occupy,soldier,ingr com,intergraph,lebanon\n",
      "\n",
      "Topic #5:\n",
      "sandvik,detector,expo,umn,umn edu,dartmouth,kent,expo lcs,radar,apple com,uoknor,uoknor edu,sdsu,xpert,internet line,mit edu,radar detector,organization internet,xpert expo,lcs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# con questo stampo:\n",
    "\n",
    "for topic_idx, topic in enumerate(H):\n",
    "    print \"Topic #%d:\" % topic_idx\n",
    "    print \",\".join([feature_names[i] for i in topic.argsort()[:-21:-1]])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
